{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bd4e2f63-28c5-4cfd-890a-c74b6146a290",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchvision import datasets,transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec9bf7b4-46b4-40c9-ad39-e80030a597b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b87c77c0-6db5-442b-b7a0-21af2e5cb8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8819d6ae-c39c-48d9-a198-464cda591de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "86449e7b-2a57-4c51-a909-401224c7585b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ffd5881f-d1af-48e7-acb4-c1877331a586",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4b587b7f-5dba-48a4-9b47-013349f1a0c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset + Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "01fb3207-11e6-4851-965f-118903c6a1cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/ortalhanuna/my-code/.venv/lib/python3.13/site-packages/certifi/cacert.pem\n"
     ]
    }
   ],
   "source": [
    "import certifi\n",
    "print(certifi.where()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "57c68ca0-65c7-4cec-9bb4-3e133064c8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = datasets.CIFAR10(root='./data', train=True,download=True,transform=transform)\n",
    "test_dataset =  datasets.CIFAR10(root ='./data', train=False,download=True,transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7687cfe6-0a90-42f2-b7c6-a28009990c0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "22a0a7e4-3517-459b-9676-27194ee78da4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset CIFAR10\n",
      "    Number of datapoints: 50000\n",
      "    Root location: ./data\n",
      "    Split: Train\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "               ToTensor()\n",
      "               Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
      "           )\n",
      "Dataset CIFAR10\n",
      "    Number of datapoints: 10000\n",
      "    Root location: ./data\n",
      "    Split: Train\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "               ToTensor()\n",
      "               Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
      "           )\n"
     ]
    }
   ],
   "source": [
    "def filter_cars_only(ds):\n",
    "    mask = np.isin(ds.targets,[1,9])\n",
    "    ds.data , ds.targets = ds.data[mask],np.array(ds.targets)[mask]\n",
    "    ds.targets = [0 if y==1 else 1 for y in ds.targets if y in [1,9]]\n",
    "    return ds\n",
    "\n",
    "print(train_dataset)\n",
    "train_dataset = filter_cars_only(train_dataset)\n",
    "print(train_dataset)\n",
    "\n",
    "test_dataset = filter_cars_only(test_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0f8a76be-87e4-43a7-b9da-a55431cc7b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=64,shuffle=True)\n",
    "test_loader = DataLoader(test_dataset,batch_size=64,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e6a6dd80-b13d-422c-a747-a97470c143ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = {0:'automobile', 1: 'truck'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "32474dae-adf5-437a-8e91-63fea03be701",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "69fb0496-9f16-4cf1-8f38-8aa684b3fb5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuantizedVehicleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.quant = torch.quantization.QuantStub()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3,16,3,1)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(16,32,3,1)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        \n",
    "        self.pool = nn.MaxPool2d(2,2)\n",
    "        \n",
    "        self.fc1 = nn.Linear(32*14*14,64)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        \n",
    "        self.fc2 = nn.Linear(64,3)         \n",
    "\n",
    "        self.dequant = torch.quantization.DeQuantStub()\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.quant(x)            \n",
    "        x = self.conv1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.pool(x)\n",
    "        x = torch.flatten(x,1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.dequant(x)         \n",
    "        return x\n",
    "\n",
    "# torch.Size([64, 3, 32, 32])\n",
    "# torch.Size([64, 3, 32, 32])\n",
    "# torch.Size([64, 16, 30, 30])\n",
    "# torch.Size([64, 16, 30, 30])\n",
    "# torch.Size([64, 32, 28, 28])\n",
    "# torch.Size([64, 32, 28, 28])\n",
    "# torch.Size([64, 32, 14, 14])\n",
    "# torch.Size([64, 6272])\n",
    "# torch.Size([64, 64])\n",
    "# torch.Size([64, 64])\n",
    "# torch.Size([64, 3])\n",
    "# torch.Size([64, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f613a39c-36ad-4c30-ae9c-0b18bacb297a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = QuantizedVehicleCNN()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6c1ebb4b-4f30-4ba4-b5db-d03a657086f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## loss + optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6ec73cbb-f7f7-4563-aa60-76cf03164f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "062fbbca-b263-49fc-bdc1-9f336877e604",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f50a83c2-d0e8-4e6b-910d-749c3513920c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.4537\n",
      "Epoch 2, Loss: 0.2510\n",
      "Epoch 3, Loss: 0.3068\n",
      "Epoch 4, Loss: 0.1156\n",
      "Epoch 5, Loss: 0.1509\n",
      "Epoch 6, Loss: 0.0385\n",
      "Epoch 7, Loss: 0.0611\n",
      "Epoch 8, Loss: 0.0309\n",
      "Epoch 9, Loss: 0.1309\n",
      "Epoch 10, Loss: 0.0124\n",
      "Epoch 11, Loss: 0.0028\n",
      "Epoch 12, Loss: 0.0135\n",
      "Epoch 13, Loss: 0.0021\n",
      "Epoch 14, Loss: 0.0028\n",
      "Epoch 15, Loss: 0.0043\n",
      "Epoch 16, Loss: 0.0004\n",
      "Epoch 17, Loss: 0.0001\n",
      "Epoch 18, Loss: 0.0014\n",
      "Epoch 19, Loss: 0.0003\n",
      "Epoch 20, Loss: 0.0004\n",
      "Epoch 21, Loss: 0.0006\n",
      "Epoch 22, Loss: 0.0001\n",
      "Epoch 23, Loss: 0.0003\n",
      "Epoch 24, Loss: 0.0002\n",
      "Epoch 25, Loss: 0.0003\n",
      "Epoch 26, Loss: 0.0002\n",
      "Epoch 27, Loss: 0.0001\n",
      "Epoch 28, Loss: 0.0001\n",
      "Epoch 29, Loss: 0.0002\n",
      "Epoch 30, Loss: 0.0002\n",
      "Epoch 31, Loss: 0.0003\n",
      "Epoch 32, Loss: 0.0000\n",
      "Epoch 33, Loss: 0.0001\n",
      "Epoch 34, Loss: 0.0000\n",
      "Epoch 35, Loss: 0.0002\n",
      "Epoch 36, Loss: 0.0001\n",
      "Epoch 37, Loss: 0.0000\n",
      "Epoch 38, Loss: 0.0001\n",
      "Epoch 39, Loss: 0.0001\n",
      "Epoch 40, Loss: 0.0000\n",
      "Epoch 41, Loss: 0.0000\n",
      "Epoch 42, Loss: 0.0001\n",
      "Epoch 43, Loss: 0.0000\n",
      "Epoch 44, Loss: 0.0000\n",
      "Epoch 45, Loss: 0.0000\n",
      "Epoch 46, Loss: 0.0001\n",
      "Epoch 47, Loss: 0.0000\n",
      "Epoch 48, Loss: 0.0000\n",
      "Epoch 49, Loss: 0.0000\n",
      "Epoch 50, Loss: 0.0000\n"
     ]
    }
   ],
   "source": [
    "epochs = 50\n",
    "for epoch in range(epochs):\n",
    "    for x_batch, y_batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(x_batch)\n",
    "        loss = criterion(outputs,y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f\"Epoch {epoch+1}, Loss: {loss.item():.4f}\")\n",
    " # x-pics ,  y-real_results,   outputs-model_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b68d6fa5-eda0-46f9-9421-c730fa887364",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for x_batch, y_batch in test_loader:\n",
    "        outputs = model(x_batch)\n",
    "        _, preds = torch.max(outputs,1)\n",
    "        correct += (preds == y_batch).sum().item()\n",
    "        total += y_batch.size(0)\n",
    "print(\"Test Accuracy :\", correct/total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e316199f-fd2f-4fab-9153-bade47993b64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 1, 2],\n",
      "        [3, 4, 5]])\n",
      "tensor([[0, 1, 2],\n",
      "        [3, 4, 5]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "x = torch.arange(6)       # [0,1,2,3,4,5]\n",
    "y = x.view(2,3)           # טוב, כל הנתונים רציפים\n",
    "print(y)\n",
    "\n",
    "z = x.t().reshape(2,3)    # אם הטנזור לא רציף, reshape() ייצור עותק\n",
    "print(z)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee9a60ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
