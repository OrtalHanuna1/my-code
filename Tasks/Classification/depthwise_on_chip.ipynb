{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d09f8e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d84c0dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "cd55115b",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "train_ds = datasets.MNIST('.',train=True,transform=transform,download=True)\n",
    "test_ds = datasets.MNIST('.',train=False,transform=transform,download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "050fe38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_ds,128,shuffle=True)\n",
    "test_loader = DataLoader(test_ds,128,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "cb36eb7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "img, label = train_ds[0]\n",
    "plt.imshow(img.squeeze(), cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "6f6d20c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SmallModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.depthwise1 = nn.Conv2d(1,1,3,1,1,groups=1)\n",
    "        self.pointwise1 = nn.Conv2d(1,16,1)\n",
    "        self.depthwise2 = nn.Conv2d(16,16,3,1,1,groups=1)\n",
    "        self.pointwise2 = nn.Conv2d(16,32,1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.pooling = nn.MaxPool2d(2)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc = nn.Linear(32*7*7,10)\n",
    "        \n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.depthwise1(x)\n",
    "        x = self.pointwise1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pooling(x)\n",
    "\n",
    "        x = self.depthwise2(x)\n",
    "        x = self.pointwise2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pooling(x)\n",
    "\n",
    "\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc(x)\n",
    "\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4708ac4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model  = SmallModel().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr =1e-3)\n",
    "criterion = nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "8fb13c7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: epoch- 0 loss- 1.9635611772537231\n",
      "train: epoch- 0 loss- 1.8779984712600708\n",
      "train: epoch- 0 loss- 1.8802233934402466\n",
      "train: epoch- 0 loss- 1.791225790977478\n",
      "train: epoch- 0 loss- 1.749695897102356\n",
      "train: epoch- 0 loss- 1.7367814779281616\n",
      "train: epoch- 0 loss- 1.7647364139556885\n",
      "train: epoch- 0 loss- 1.6930867433547974\n",
      "train: epoch- 0 loss- 1.6628568172454834\n",
      "train: epoch- 0 loss- 1.5908571481704712\n",
      "train: epoch- 0 loss- 1.5972936153411865\n",
      "train: epoch- 0 loss- 1.6022238731384277\n",
      "train: epoch- 0 loss- 1.5629459619522095\n",
      "train: epoch- 0 loss- 1.4564836025238037\n",
      "train: epoch- 0 loss- 1.4211452007293701\n",
      "train: epoch- 0 loss- 1.411738634109497\n",
      "train: epoch- 0 loss- 1.4141845703125\n",
      "train: epoch- 0 loss- 1.3585628271102905\n",
      "train: epoch- 0 loss- 1.3636906147003174\n",
      "train: epoch- 0 loss- 1.3106640577316284\n",
      "train: epoch- 0 loss- 1.362160325050354\n",
      "train: epoch- 0 loss- 1.268776535987854\n",
      "train: epoch- 0 loss- 1.0951611995697021\n",
      "train: epoch- 0 loss- 1.1929583549499512\n",
      "train: epoch- 0 loss- 1.1923314332962036\n",
      "train: epoch- 0 loss- 1.0966317653656006\n",
      "train: epoch- 0 loss- 1.0007867813110352\n",
      "train: epoch- 0 loss- 1.0165812969207764\n",
      "train: epoch- 0 loss- 1.0994267463684082\n",
      "train: epoch- 0 loss- 1.0109844207763672\n",
      "train: epoch- 0 loss- 0.9822605848312378\n",
      "train: epoch- 0 loss- 0.9697162508964539\n",
      "train: epoch- 0 loss- 0.8636026382446289\n",
      "train: epoch- 0 loss- 0.9085760116577148\n",
      "train: epoch- 0 loss- 0.8781387805938721\n",
      "train: epoch- 0 loss- 0.8552083373069763\n",
      "train: epoch- 0 loss- 0.7802836894989014\n",
      "train: epoch- 0 loss- 0.7609164714813232\n",
      "train: epoch- 0 loss- 0.7710241675376892\n",
      "train: epoch- 0 loss- 0.8161682486534119\n",
      "train: epoch- 0 loss- 0.8449932932853699\n",
      "train: epoch- 0 loss- 0.6975006461143494\n",
      "train: epoch- 0 loss- 0.7807005643844604\n",
      "train: epoch- 0 loss- 0.8588730692863464\n",
      "train: epoch- 0 loss- 0.7028430104255676\n",
      "train: epoch- 0 loss- 0.7078397870063782\n",
      "train: epoch- 0 loss- 0.7016534209251404\n",
      "train: epoch- 0 loss- 0.6407799124717712\n",
      "train: epoch- 0 loss- 0.7770423889160156\n",
      "train: epoch- 0 loss- 0.5714551210403442\n",
      "train: epoch- 0 loss- 0.7083072066307068\n",
      "train: epoch- 0 loss- 0.6404004693031311\n",
      "train: epoch- 0 loss- 0.6203212141990662\n",
      "train: epoch- 0 loss- 0.6558526158332825\n",
      "train: epoch- 0 loss- 0.7339319586753845\n",
      "train: epoch- 0 loss- 0.5885610580444336\n",
      "train: epoch- 0 loss- 0.4521279036998749\n",
      "train: epoch- 0 loss- 0.49557095766067505\n",
      "train: epoch- 0 loss- 0.5333037376403809\n",
      "train: epoch- 0 loss- 0.4599939286708832\n",
      "train: epoch- 0 loss- 0.591407299041748\n",
      "train: epoch- 0 loss- 0.5197997093200684\n",
      "train: epoch- 0 loss- 0.6215196251869202\n",
      "train: epoch- 0 loss- 0.5241169333457947\n",
      "train: epoch- 0 loss- 0.4557296931743622\n",
      "train: epoch- 0 loss- 0.58983314037323\n",
      "train: epoch- 0 loss- 0.437507301568985\n",
      "train: epoch- 0 loss- 0.5468396544456482\n",
      "train: epoch- 0 loss- 0.4518512189388275\n",
      "train: epoch- 0 loss- 0.5621039271354675\n",
      "train: epoch- 0 loss- 0.6549322009086609\n",
      "train: epoch- 0 loss- 0.5435320734977722\n",
      "train: epoch- 0 loss- 0.5062891840934753\n",
      "train: epoch- 0 loss- 0.4693931043148041\n",
      "train: epoch- 0 loss- 0.547934353351593\n",
      "train: epoch- 0 loss- 0.5035797357559204\n",
      "train: epoch- 0 loss- 0.4455921947956085\n",
      "train: epoch- 0 loss- 0.461650013923645\n",
      "train: epoch- 0 loss- 0.49305787682533264\n",
      "train: epoch- 0 loss- 0.3852488100528717\n",
      "train: epoch- 0 loss- 0.5277285575866699\n",
      "train: epoch- 0 loss- 0.5087443590164185\n",
      "train: epoch- 0 loss- 0.5317292809486389\n",
      "train: epoch- 0 loss- 0.5264553427696228\n",
      "train: epoch- 0 loss- 0.5771850347518921\n",
      "train: epoch- 0 loss- 0.4784700870513916\n",
      "train: epoch- 0 loss- 0.41833633184432983\n",
      "train: epoch- 0 loss- 0.4736998379230499\n",
      "train: epoch- 0 loss- 0.44090554118156433\n",
      "train: epoch- 0 loss- 0.42327767610549927\n",
      "train: epoch- 0 loss- 0.47349613904953003\n",
      "train: epoch- 0 loss- 0.3733985126018524\n",
      "train: epoch- 0 loss- 0.4352097809314728\n",
      "train: epoch- 0 loss- 0.41437187790870667\n",
      "train: epoch- 0 loss- 0.3985445201396942\n",
      "train: epoch- 0 loss- 0.3636830449104309\n",
      "train: epoch- 0 loss- 0.4575929343700409\n",
      "train: epoch- 0 loss- 0.4134403467178345\n",
      "train: epoch- 0 loss- 0.48821383714675903\n",
      "train: epoch- 0 loss- 0.37439918518066406\n",
      "train: epoch- 0 loss- 0.47864747047424316\n",
      "train: epoch- 0 loss- 0.4278261661529541\n",
      "train: epoch- 0 loss- 0.41726821660995483\n",
      "train: epoch- 0 loss- 0.47768017649650574\n",
      "train: epoch- 0 loss- 0.44580745697021484\n",
      "train: epoch- 0 loss- 0.2605855166912079\n",
      "train: epoch- 0 loss- 0.4177819788455963\n",
      "train: epoch- 0 loss- 0.46678441762924194\n",
      "train: epoch- 0 loss- 0.5168277025222778\n",
      "train: epoch- 0 loss- 0.485566109418869\n",
      "train: epoch- 0 loss- 0.42096462845802307\n",
      "train: epoch- 0 loss- 0.37968990206718445\n",
      "train: epoch- 0 loss- 0.3991614282131195\n",
      "train: epoch- 0 loss- 0.45849958062171936\n",
      "train: epoch- 0 loss- 0.3257709741592407\n",
      "train: epoch- 0 loss- 0.4808375835418701\n",
      "train: epoch- 0 loss- 0.32503247261047363\n",
      "train: epoch- 0 loss- 0.505358099937439\n",
      "train: epoch- 0 loss- 0.565682053565979\n",
      "train: epoch- 0 loss- 0.4269421398639679\n",
      "train: epoch- 0 loss- 0.4308605492115021\n",
      "train: epoch- 0 loss- 0.42310500144958496\n",
      "train: epoch- 0 loss- 0.35157960653305054\n",
      "train: epoch- 0 loss- 0.35543087124824524\n",
      "train: epoch- 0 loss- 0.3968091905117035\n",
      "train: epoch- 0 loss- 0.3450276553630829\n",
      "train: epoch- 0 loss- 0.42085471749305725\n",
      "train: epoch- 0 loss- 0.4062087833881378\n",
      "train: epoch- 0 loss- 0.40178731083869934\n",
      "train: epoch- 0 loss- 0.3129596412181854\n",
      "train: epoch- 0 loss- 0.35445529222488403\n",
      "train: epoch- 0 loss- 0.2870262861251831\n",
      "train: epoch- 0 loss- 0.3960956335067749\n",
      "train: epoch- 0 loss- 0.49163517355918884\n",
      "train: epoch- 0 loss- 0.41441014409065247\n",
      "train: epoch- 0 loss- 0.35787728428840637\n",
      "train: epoch- 0 loss- 0.49514320492744446\n",
      "train: epoch- 0 loss- 0.3546365797519684\n",
      "train: epoch- 0 loss- 0.48543456196784973\n",
      "train: epoch- 0 loss- 0.5438457131385803\n",
      "train: epoch- 0 loss- 0.583046019077301\n",
      "train: epoch- 0 loss- 0.3435044586658478\n",
      "train: epoch- 0 loss- 0.45666831731796265\n",
      "train: epoch- 0 loss- 0.3119223713874817\n",
      "train: epoch- 0 loss- 0.31898269057273865\n",
      "train: epoch- 0 loss- 0.316203773021698\n",
      "train: epoch- 0 loss- 0.3270096182823181\n",
      "train: epoch- 0 loss- 0.32870733737945557\n",
      "train: epoch- 0 loss- 0.38074254989624023\n",
      "train: epoch- 0 loss- 0.25416436791419983\n",
      "train: epoch- 0 loss- 0.3862428367137909\n",
      "train: epoch- 0 loss- 0.3060173988342285\n",
      "train: epoch- 0 loss- 0.4106493294239044\n",
      "train: epoch- 0 loss- 0.3314834237098694\n",
      "train: epoch- 0 loss- 0.38249671459198\n",
      "train: epoch- 0 loss- 0.3453204035758972\n",
      "train: epoch- 0 loss- 0.4262503683567047\n",
      "train: epoch- 0 loss- 0.29025736451148987\n",
      "train: epoch- 0 loss- 0.40021443367004395\n",
      "train: epoch- 0 loss- 0.4467304050922394\n",
      "train: epoch- 0 loss- 0.2987523376941681\n",
      "train: epoch- 0 loss- 0.31396371126174927\n",
      "train: epoch- 0 loss- 0.36786141991615295\n",
      "train: epoch- 0 loss- 0.4491359293460846\n",
      "train: epoch- 0 loss- 0.5070834159851074\n",
      "train: epoch- 0 loss- 0.2751446068286896\n",
      "train: epoch- 0 loss- 0.33870092034339905\n",
      "train: epoch- 0 loss- 0.4341171085834503\n",
      "train: epoch- 0 loss- 0.25582408905029297\n",
      "train: epoch- 0 loss- 0.27523285150527954\n",
      "train: epoch- 0 loss- 0.3042367100715637\n",
      "train: epoch- 0 loss- 0.4388186037540436\n",
      "train: epoch- 0 loss- 0.23690856993198395\n",
      "train: epoch- 0 loss- 0.5173704028129578\n",
      "train: epoch- 0 loss- 0.38475465774536133\n",
      "train: epoch- 0 loss- 0.39709827303886414\n",
      "train: epoch- 0 loss- 0.32968178391456604\n",
      "train: epoch- 0 loss- 0.45099130272865295\n",
      "train: epoch- 0 loss- 0.29084980487823486\n",
      "train: epoch- 0 loss- 0.29232102632522583\n",
      "train: epoch- 0 loss- 0.37159469723701477\n",
      "train: epoch- 0 loss- 0.3116829991340637\n",
      "train: epoch- 0 loss- 0.3323671817779541\n",
      "train: epoch- 0 loss- 0.438639760017395\n",
      "train: epoch- 0 loss- 0.40203410387039185\n",
      "train: epoch- 0 loss- 0.5011260509490967\n",
      "train: epoch- 0 loss- 0.25190383195877075\n",
      "train: epoch- 0 loss- 0.3604258894920349\n",
      "train: epoch- 0 loss- 0.23746654391288757\n",
      "train: epoch- 0 loss- 0.3663133382797241\n",
      "train: epoch- 0 loss- 0.3674141764640808\n",
      "train: epoch- 0 loss- 0.31711629033088684\n",
      "train: epoch- 0 loss- 0.3621070086956024\n",
      "train: epoch- 0 loss- 0.3629898428916931\n",
      "train: epoch- 0 loss- 0.3819009065628052\n",
      "train: epoch- 0 loss- 0.35831570625305176\n",
      "train: epoch- 0 loss- 0.37996581196784973\n",
      "train: epoch- 0 loss- 0.48981910943984985\n",
      "train: epoch- 0 loss- 0.3415423333644867\n",
      "train: epoch- 0 loss- 0.2422575056552887\n",
      "train: epoch- 0 loss- 0.38107848167419434\n",
      "train: epoch- 0 loss- 0.29400986433029175\n",
      "train: epoch- 0 loss- 0.31564775109291077\n",
      "train: epoch- 0 loss- 0.43944746255874634\n",
      "train: epoch- 0 loss- 0.27827781438827515\n",
      "train: epoch- 0 loss- 0.23435235023498535\n",
      "train: epoch- 0 loss- 0.25354713201522827\n",
      "train: epoch- 0 loss- 0.28766587376594543\n",
      "train: epoch- 0 loss- 0.23752154409885406\n",
      "train: epoch- 0 loss- 0.2597275674343109\n",
      "train: epoch- 0 loss- 0.26611825823783875\n",
      "train: epoch- 0 loss- 0.3914216160774231\n",
      "train: epoch- 0 loss- 0.2586064636707306\n",
      "train: epoch- 0 loss- 0.2934010326862335\n",
      "train: epoch- 0 loss- 0.4421089291572571\n",
      "train: epoch- 0 loss- 0.23413591086864471\n",
      "train: epoch- 0 loss- 0.28520360589027405\n",
      "train: epoch- 0 loss- 0.3273174464702606\n",
      "train: epoch- 0 loss- 0.3998976945877075\n",
      "train: epoch- 0 loss- 0.309076189994812\n",
      "train: epoch- 0 loss- 0.2366030365228653\n",
      "train: epoch- 0 loss- 0.260470986366272\n",
      "train: epoch- 0 loss- 0.24122335016727448\n",
      "train: epoch- 0 loss- 0.2128446400165558\n",
      "train: epoch- 0 loss- 0.3978199362754822\n",
      "train: epoch- 0 loss- 0.3113638162612915\n",
      "train: epoch- 0 loss- 0.3363174796104431\n",
      "train: epoch- 0 loss- 0.2651940584182739\n",
      "train: epoch- 0 loss- 0.25975680351257324\n",
      "train: epoch- 0 loss- 0.23188595473766327\n",
      "train: epoch- 0 loss- 0.4302006661891937\n",
      "train: epoch- 0 loss- 0.33258146047592163\n",
      "train: epoch- 0 loss- 0.2919132113456726\n",
      "train: epoch- 0 loss- 0.2525334656238556\n",
      "train: epoch- 0 loss- 0.3468477427959442\n",
      "train: epoch- 0 loss- 0.20429283380508423\n",
      "train: epoch- 0 loss- 0.36053574085235596\n",
      "train: epoch- 0 loss- 0.23928257822990417\n",
      "train: epoch- 0 loss- 0.19250820577144623\n",
      "train: epoch- 0 loss- 0.2552550435066223\n",
      "train: epoch- 0 loss- 0.27644822001457214\n",
      "train: epoch- 0 loss- 0.22008492052555084\n",
      "train: epoch- 0 loss- 0.2701188921928406\n",
      "train: epoch- 0 loss- 0.20719677209854126\n",
      "train: epoch- 0 loss- 0.2800348401069641\n",
      "train: epoch- 0 loss- 0.24079208076000214\n",
      "train: epoch- 0 loss- 0.1816575825214386\n",
      "train: epoch- 0 loss- 0.42234423756599426\n",
      "train: epoch- 0 loss- 0.30171018838882446\n",
      "train: epoch- 0 loss- 0.2902984321117401\n",
      "train: epoch- 0 loss- 0.3491590917110443\n",
      "train: epoch- 0 loss- 0.2690889239311218\n",
      "train: epoch- 0 loss- 0.4140405058860779\n",
      "train: epoch- 0 loss- 0.1522727608680725\n",
      "train: epoch- 0 loss- 0.22689597308635712\n",
      "train: epoch- 0 loss- 0.2585553526878357\n",
      "train: epoch- 0 loss- 0.18470975756645203\n",
      "train: epoch- 0 loss- 0.4437953531742096\n",
      "train: epoch- 0 loss- 0.2169121503829956\n",
      "train: epoch- 0 loss- 0.31559088826179504\n",
      "train: epoch- 0 loss- 0.39468488097190857\n",
      "train: epoch- 0 loss- 0.17514905333518982\n",
      "train: epoch- 0 loss- 0.3598647117614746\n",
      "train: epoch- 0 loss- 0.21138058602809906\n",
      "train: epoch- 0 loss- 0.23035727441310883\n",
      "train: epoch- 0 loss- 0.3319380581378937\n",
      "train: epoch- 0 loss- 0.2889162600040436\n",
      "train: epoch- 0 loss- 0.33900654315948486\n",
      "train: epoch- 0 loss- 0.216916024684906\n",
      "train: epoch- 0 loss- 0.1739402860403061\n",
      "train: epoch- 0 loss- 0.4748193621635437\n",
      "train: epoch- 0 loss- 0.21678893268108368\n",
      "train: epoch- 0 loss- 0.2427767664194107\n",
      "train: epoch- 0 loss- 0.25686049461364746\n",
      "train: epoch- 0 loss- 0.2966313362121582\n",
      "train: epoch- 0 loss- 0.2760584354400635\n",
      "train: epoch- 0 loss- 0.1479271501302719\n",
      "train: epoch- 0 loss- 0.34908756613731384\n",
      "train: epoch- 0 loss- 0.3350631296634674\n",
      "train: epoch- 0 loss- 0.4354133903980255\n",
      "train: epoch- 0 loss- 0.33671537041664124\n",
      "train: epoch- 0 loss- 0.27146515250205994\n",
      "train: epoch- 0 loss- 0.23571667075157166\n",
      "train: epoch- 0 loss- 0.31378844380378723\n",
      "train: epoch- 0 loss- 0.24957437813282013\n",
      "train: epoch- 0 loss- 0.2055170089006424\n",
      "train: epoch- 0 loss- 0.27061915397644043\n",
      "train: epoch- 0 loss- 0.1535906046628952\n",
      "train: epoch- 0 loss- 0.27946850657463074\n",
      "train: epoch- 0 loss- 0.4287443459033966\n",
      "train: epoch- 0 loss- 0.26451390981674194\n",
      "train: epoch- 0 loss- 0.19982536137104034\n",
      "train: epoch- 0 loss- 0.35321980714797974\n",
      "train: epoch- 0 loss- 0.23948132991790771\n",
      "train: epoch- 0 loss- 0.3221661150455475\n",
      "train: epoch- 0 loss- 0.31167706847190857\n",
      "train: epoch- 0 loss- 0.17127303779125214\n",
      "train: epoch- 0 loss- 0.31866681575775146\n",
      "train: epoch- 0 loss- 0.300445556640625\n",
      "train: epoch- 0 loss- 0.2308194488286972\n",
      "train: epoch- 0 loss- 0.2926716208457947\n",
      "train: epoch- 0 loss- 0.13588041067123413\n",
      "train: epoch- 0 loss- 0.29548338055610657\n",
      "train: epoch- 0 loss- 0.2743678390979767\n",
      "train: epoch- 0 loss- 0.24429453909397125\n",
      "train: epoch- 0 loss- 0.18842290341854095\n",
      "train: epoch- 0 loss- 0.1477792114019394\n",
      "train: epoch- 0 loss- 0.2661052346229553\n",
      "train: epoch- 0 loss- 0.3543768525123596\n",
      "train: epoch- 0 loss- 0.3863791525363922\n",
      "train: epoch- 0 loss- 0.19652563333511353\n",
      "train: epoch- 0 loss- 0.26692697405815125\n",
      "train: epoch- 0 loss- 0.24651198089122772\n",
      "train: epoch- 0 loss- 0.30941012501716614\n",
      "train: epoch- 0 loss- 0.2984464466571808\n",
      "train: epoch- 0 loss- 0.1882672756910324\n",
      "train: epoch- 0 loss- 0.2849418818950653\n",
      "train: epoch- 0 loss- 0.18991084396839142\n",
      "train: epoch- 0 loss- 0.38193705677986145\n",
      "train: epoch- 0 loss- 0.3715469241142273\n",
      "train: epoch- 0 loss- 0.2694242298603058\n",
      "train: epoch- 0 loss- 0.2619721591472626\n",
      "train: epoch- 0 loss- 0.18909229338169098\n",
      "train: epoch- 0 loss- 0.2773810625076294\n",
      "train: epoch- 0 loss- 0.22791218757629395\n",
      "train: epoch- 0 loss- 0.33203062415122986\n",
      "train: epoch- 0 loss- 0.4031665325164795\n",
      "train: epoch- 0 loss- 0.3270491361618042\n",
      "train: epoch- 0 loss- 0.2866937816143036\n",
      "train: epoch- 0 loss- 0.33062729239463806\n",
      "train: epoch- 0 loss- 0.1892959177494049\n",
      "train: epoch- 0 loss- 0.21895405650138855\n",
      "train: epoch- 0 loss- 0.33191967010498047\n",
      "train: epoch- 0 loss- 0.317460834980011\n",
      "train: epoch- 0 loss- 0.23875552415847778\n",
      "train: epoch- 0 loss- 0.2946605384349823\n",
      "train: epoch- 0 loss- 0.1455502212047577\n",
      "train: epoch- 0 loss- 0.2625921964645386\n",
      "train: epoch- 0 loss- 0.12300226092338562\n",
      "train: epoch- 0 loss- 0.2119016945362091\n",
      "train: epoch- 0 loss- 0.21857979893684387\n",
      "train: epoch- 0 loss- 0.33208343386650085\n",
      "train: epoch- 0 loss- 0.34893494844436646\n",
      "train: epoch- 0 loss- 0.3378203213214874\n",
      "train: epoch- 0 loss- 0.1978204995393753\n",
      "train: epoch- 0 loss- 0.2341739386320114\n",
      "train: epoch- 0 loss- 0.27400147914886475\n",
      "train: epoch- 0 loss- 0.23320642113685608\n",
      "train: epoch- 0 loss- 0.23985649645328522\n",
      "train: epoch- 0 loss- 0.20876044034957886\n",
      "train: epoch- 0 loss- 0.2025952786207199\n",
      "train: epoch- 0 loss- 0.13799980282783508\n",
      "train: epoch- 0 loss- 0.15075692534446716\n",
      "train: epoch- 0 loss- 0.1699841469526291\n",
      "train: epoch- 0 loss- 0.23387984931468964\n",
      "train: epoch- 0 loss- 0.3183336555957794\n",
      "train: epoch- 0 loss- 0.18613439798355103\n",
      "train: epoch- 0 loss- 0.22382593154907227\n",
      "train: epoch- 0 loss- 0.25543293356895447\n",
      "train: epoch- 0 loss- 0.1327969878911972\n",
      "train: epoch- 0 loss- 0.2250414341688156\n",
      "train: epoch- 0 loss- 0.24583208560943604\n",
      "train: epoch- 0 loss- 0.22423556447029114\n",
      "train: epoch- 0 loss- 0.195363387465477\n",
      "train: epoch- 0 loss- 0.29906460642814636\n",
      "train: epoch- 0 loss- 0.1933288723230362\n",
      "train: epoch- 0 loss- 0.14078781008720398\n",
      "train: epoch- 0 loss- 0.13397040963172913\n",
      "train: epoch- 0 loss- 0.1784454733133316\n",
      "train: epoch- 0 loss- 0.206377774477005\n",
      "train: epoch- 0 loss- 0.1526578664779663\n",
      "train: epoch- 0 loss- 0.30690449476242065\n",
      "train: epoch- 0 loss- 0.26721224188804626\n",
      "train: epoch- 0 loss- 0.1657331883907318\n",
      "train: epoch- 0 loss- 0.1960894912481308\n",
      "train: epoch- 0 loss- 0.12493925541639328\n",
      "train: epoch- 0 loss- 0.1686856746673584\n",
      "train: epoch- 0 loss- 0.3232397735118866\n",
      "train: epoch- 0 loss- 0.19369931519031525\n",
      "train: epoch- 0 loss- 0.2186642438173294\n",
      "train: epoch- 0 loss- 0.1979520469903946\n",
      "train: epoch- 0 loss- 0.16162319481372833\n",
      "train: epoch- 0 loss- 0.17868946492671967\n",
      "train: epoch- 0 loss- 0.352875679731369\n",
      "train: epoch- 0 loss- 0.15946422517299652\n",
      "train: epoch- 0 loss- 0.2811756730079651\n",
      "train: epoch- 0 loss- 0.3053840398788452\n",
      "train: epoch- 0 loss- 0.1437927782535553\n",
      "train: epoch- 0 loss- 0.1873001903295517\n",
      "train: epoch- 0 loss- 0.20831023156642914\n",
      "train: epoch- 0 loss- 0.15067537128925323\n",
      "train: epoch- 0 loss- 0.20322619378566742\n",
      "train: epoch- 0 loss- 0.3177315592765808\n",
      "train: epoch- 0 loss- 0.2880949378013611\n",
      "train: epoch- 0 loss- 0.3597698509693146\n",
      "train: epoch- 0 loss- 0.16225318610668182\n",
      "train: epoch- 0 loss- 0.273007333278656\n",
      "train: epoch- 0 loss- 0.22640688717365265\n",
      "train: epoch- 0 loss- 0.1620781123638153\n",
      "train: epoch- 0 loss- 0.2522921860218048\n",
      "train: epoch- 0 loss- 0.12401369214057922\n",
      "train: epoch- 0 loss- 0.19150225818157196\n",
      "train: epoch- 0 loss- 0.15045787394046783\n",
      "train: epoch- 0 loss- 0.24293676018714905\n",
      "train: epoch- 0 loss- 0.1502266377210617\n",
      "train: epoch- 0 loss- 0.3192284107208252\n",
      "train: epoch- 0 loss- 0.18003533780574799\n",
      "train: epoch- 0 loss- 0.22016337513923645\n",
      "train: epoch- 0 loss- 0.26752543449401855\n",
      "train: epoch- 0 loss- 0.19179192185401917\n",
      "train: epoch- 0 loss- 0.1346488893032074\n",
      "train: epoch- 0 loss- 0.34839463233947754\n",
      "train: epoch- 0 loss- 0.27901142835617065\n",
      "train: epoch- 0 loss- 0.19376297295093536\n",
      "train: epoch- 0 loss- 0.16974453628063202\n",
      "train: epoch- 0 loss- 0.12656283378601074\n",
      "train: epoch- 0 loss- 0.2005579173564911\n",
      "train: epoch- 0 loss- 0.30458036065101624\n",
      "train: epoch- 0 loss- 0.21945038437843323\n",
      "train: epoch- 0 loss- 0.23126044869422913\n",
      "train: epoch- 0 loss- 0.21777601540088654\n",
      "train: epoch- 0 loss- 0.2540985345840454\n",
      "train: epoch- 0 loss- 0.18399342894554138\n",
      "train: epoch- 0 loss- 0.34061047434806824\n",
      "train: epoch- 0 loss- 0.31465160846710205\n",
      "train: epoch- 0 loss- 0.18509531021118164\n",
      "train: epoch- 0 loss- 0.224431112408638\n",
      "train: epoch- 0 loss- 0.1182025820016861\n",
      "train: epoch- 0 loss- 0.25087857246398926\n",
      "train: epoch- 0 loss- 0.19109246134757996\n",
      "train: epoch- 0 loss- 0.2331913560628891\n",
      "train: epoch- 0 loss- 0.2052498608827591\n",
      "train: epoch- 0 loss- 0.27053558826446533\n",
      "train: epoch- 0 loss- 0.1980537623167038\n",
      "train: epoch- 0 loss- 0.29697737097740173\n",
      "train: epoch- 0 loss- 0.22807829082012177\n",
      "train: epoch- 0 loss- 0.22415462136268616\n",
      "train: epoch- 0 loss- 0.2688158452510834\n",
      "train: epoch- 0 loss- 0.3172587752342224\n",
      "train: epoch- 0 loss- 0.12583379447460175\n",
      "train: epoch- 0 loss- 0.2078613042831421\n",
      "train: epoch- 0 loss- 0.23105990886688232\n",
      "train: epoch- 0 loss- 0.3669068217277527\n",
      "train: epoch- 0 loss- 0.19819074869155884\n",
      "train: epoch- 0 loss- 0.2462339550256729\n",
      "train: epoch- 0 loss- 0.3919536769390106\n",
      "train: epoch- 0 loss- 0.20909208059310913\n",
      "train: epoch- 0 loss- 0.09898236393928528\n",
      "train: epoch- 0 loss- 0.3574323356151581\n",
      "train: epoch- 0 loss- 0.17251929640769958\n",
      "train: epoch- 0 loss- 0.25183752179145813\n",
      "train: epoch- 0 loss- 0.17052434384822845\n",
      "train: epoch- 0 loss- 0.26465779542922974\n",
      "train: epoch- 0 loss- 0.35886725783348083\n",
      "train: epoch- 0 loss- 0.13650940358638763\n",
      "train: epoch- 0 loss- 0.19210684299468994\n",
      "train: epoch- 0 loss- 0.20819158852100372\n",
      "train: epoch- 0 loss- 0.11754870414733887\n",
      "train: epoch- 0 loss- 0.234236940741539\n",
      "train: epoch- 0 loss- 0.2119070142507553\n",
      "train: epoch- 0 loss- 0.17969053983688354\n",
      "train: epoch- 0 loss- 0.1580701619386673\n",
      "train: epoch- 0 loss- 0.17246150970458984\n",
      "train: epoch- 0 loss- 0.17450600862503052\n",
      "train: epoch- 0 loss- 0.21345394849777222\n",
      "train: epoch- 0 loss- 0.17250798642635345\n",
      "train: epoch- 0 loss- 0.17105185985565186\n",
      "train: epoch- 0 loss- 0.1778467893600464\n",
      "train: epoch- 0 loss- 0.2292238473892212\n",
      "epoch 0: acc = 0.9405\n",
      "train: epoch- 1 loss- 0.1796877086162567\n",
      "train: epoch- 1 loss- 0.1387755274772644\n",
      "train: epoch- 1 loss- 0.25568220019340515\n",
      "train: epoch- 1 loss- 0.2040681391954422\n",
      "train: epoch- 1 loss- 0.12878406047821045\n",
      "train: epoch- 1 loss- 0.25772255659103394\n",
      "train: epoch- 1 loss- 0.19613945484161377\n",
      "train: epoch- 1 loss- 0.19200584292411804\n",
      "train: epoch- 1 loss- 0.11296070367097855\n",
      "train: epoch- 1 loss- 0.2145421802997589\n",
      "train: epoch- 1 loss- 0.18001960217952728\n",
      "train: epoch- 1 loss- 0.15276603400707245\n",
      "train: epoch- 1 loss- 0.16201741993427277\n",
      "train: epoch- 1 loss- 0.16982337832450867\n",
      "train: epoch- 1 loss- 0.1548326015472412\n",
      "train: epoch- 1 loss- 0.21944764256477356\n",
      "train: epoch- 1 loss- 0.2119726538658142\n",
      "train: epoch- 1 loss- 0.18456830084323883\n",
      "train: epoch- 1 loss- 0.14163164794445038\n",
      "train: epoch- 1 loss- 0.09534408897161484\n",
      "train: epoch- 1 loss- 0.17557884752750397\n",
      "train: epoch- 1 loss- 0.1384451687335968\n",
      "train: epoch- 1 loss- 0.2092631608247757\n",
      "train: epoch- 1 loss- 0.13368497788906097\n",
      "train: epoch- 1 loss- 0.163489431142807\n",
      "train: epoch- 1 loss- 0.17155048251152039\n",
      "train: epoch- 1 loss- 0.2102595418691635\n",
      "train: epoch- 1 loss- 0.14755427837371826\n",
      "train: epoch- 1 loss- 0.18323783576488495\n",
      "train: epoch- 1 loss- 0.21584279835224152\n",
      "train: epoch- 1 loss- 0.30782854557037354\n",
      "train: epoch- 1 loss- 0.19360169768333435\n",
      "train: epoch- 1 loss- 0.13705866038799286\n",
      "train: epoch- 1 loss- 0.24451638758182526\n",
      "train: epoch- 1 loss- 0.13058802485466003\n",
      "train: epoch- 1 loss- 0.13209016621112823\n",
      "train: epoch- 1 loss- 0.19390542805194855\n",
      "train: epoch- 1 loss- 0.15603819489479065\n",
      "train: epoch- 1 loss- 0.15053412318229675\n",
      "train: epoch- 1 loss- 0.19695615768432617\n",
      "train: epoch- 1 loss- 0.20979949831962585\n",
      "train: epoch- 1 loss- 0.19295918941497803\n",
      "train: epoch- 1 loss- 0.2548738121986389\n",
      "train: epoch- 1 loss- 0.12491530925035477\n",
      "train: epoch- 1 loss- 0.2080228477716446\n",
      "train: epoch- 1 loss- 0.1816830188035965\n",
      "train: epoch- 1 loss- 0.1572190225124359\n",
      "train: epoch- 1 loss- 0.1718473583459854\n",
      "train: epoch- 1 loss- 0.12894664704799652\n",
      "train: epoch- 1 loss- 0.17282944917678833\n",
      "train: epoch- 1 loss- 0.26320722699165344\n",
      "train: epoch- 1 loss- 0.2483290731906891\n",
      "train: epoch- 1 loss- 0.24251008033752441\n",
      "train: epoch- 1 loss- 0.23316603899002075\n",
      "train: epoch- 1 loss- 0.13982491195201874\n",
      "train: epoch- 1 loss- 0.2447846680879593\n",
      "train: epoch- 1 loss- 0.22860291600227356\n",
      "train: epoch- 1 loss- 0.1406283676624298\n",
      "train: epoch- 1 loss- 0.30424848198890686\n",
      "train: epoch- 1 loss- 0.3044843375682831\n",
      "train: epoch- 1 loss- 0.11609421670436859\n",
      "train: epoch- 1 loss- 0.16771180927753448\n",
      "train: epoch- 1 loss- 0.22700810432434082\n",
      "train: epoch- 1 loss- 0.2091490775346756\n",
      "train: epoch- 1 loss- 0.11799471825361252\n",
      "train: epoch- 1 loss- 0.1900111734867096\n",
      "train: epoch- 1 loss- 0.14461424946784973\n",
      "train: epoch- 1 loss- 0.19701892137527466\n",
      "train: epoch- 1 loss- 0.25080278515815735\n",
      "train: epoch- 1 loss- 0.14587050676345825\n",
      "train: epoch- 1 loss- 0.161979079246521\n",
      "train: epoch- 1 loss- 0.14274214208126068\n",
      "train: epoch- 1 loss- 0.1897234469652176\n",
      "train: epoch- 1 loss- 0.2150481939315796\n",
      "train: epoch- 1 loss- 0.09396746009588242\n",
      "train: epoch- 1 loss- 0.10805882513523102\n",
      "train: epoch- 1 loss- 0.16620832681655884\n",
      "train: epoch- 1 loss- 0.18201172351837158\n",
      "train: epoch- 1 loss- 0.08195197582244873\n",
      "train: epoch- 1 loss- 0.2332206815481186\n",
      "train: epoch- 1 loss- 0.07660828530788422\n",
      "train: epoch- 1 loss- 0.21065999567508698\n",
      "train: epoch- 1 loss- 0.33520108461380005\n",
      "train: epoch- 1 loss- 0.09643158316612244\n",
      "train: epoch- 1 loss- 0.15898263454437256\n",
      "train: epoch- 1 loss- 0.18342559039592743\n",
      "train: epoch- 1 loss- 0.14236193895339966\n",
      "train: epoch- 1 loss- 0.17879663407802582\n",
      "train: epoch- 1 loss- 0.11680414527654648\n",
      "train: epoch- 1 loss- 0.30750977993011475\n",
      "train: epoch- 1 loss- 0.0973958671092987\n",
      "train: epoch- 1 loss- 0.13800214231014252\n",
      "train: epoch- 1 loss- 0.15377217531204224\n",
      "train: epoch- 1 loss- 0.18208062648773193\n",
      "train: epoch- 1 loss- 0.12474588304758072\n",
      "train: epoch- 1 loss- 0.15367436408996582\n",
      "train: epoch- 1 loss- 0.10927587747573853\n",
      "train: epoch- 1 loss- 0.11448198556900024\n",
      "train: epoch- 1 loss- 0.219576895236969\n",
      "train: epoch- 1 loss- 0.23259665071964264\n",
      "train: epoch- 1 loss- 0.20417644083499908\n",
      "train: epoch- 1 loss- 0.12091954052448273\n",
      "train: epoch- 1 loss- 0.38179174065589905\n",
      "train: epoch- 1 loss- 0.386857271194458\n",
      "train: epoch- 1 loss- 0.2207561433315277\n",
      "train: epoch- 1 loss- 0.2938607633113861\n",
      "train: epoch- 1 loss- 0.17167307436466217\n",
      "train: epoch- 1 loss- 0.2427929937839508\n",
      "train: epoch- 1 loss- 0.1388198733329773\n",
      "train: epoch- 1 loss- 0.17389342188835144\n",
      "train: epoch- 1 loss- 0.29438838362693787\n",
      "train: epoch- 1 loss- 0.3460199534893036\n",
      "train: epoch- 1 loss- 0.12522001564502716\n",
      "train: epoch- 1 loss- 0.2190191000699997\n",
      "train: epoch- 1 loss- 0.15247958898544312\n",
      "train: epoch- 1 loss- 0.21044178307056427\n",
      "train: epoch- 1 loss- 0.24745509028434753\n",
      "train: epoch- 1 loss- 0.18510711193084717\n",
      "train: epoch- 1 loss- 0.13000832498073578\n",
      "train: epoch- 1 loss- 0.05948501080274582\n",
      "train: epoch- 1 loss- 0.15098139643669128\n",
      "train: epoch- 1 loss- 0.14823350310325623\n",
      "train: epoch- 1 loss- 0.2521318793296814\n",
      "train: epoch- 1 loss- 0.1272047907114029\n",
      "train: epoch- 1 loss- 0.23520946502685547\n",
      "train: epoch- 1 loss- 0.2614849805831909\n",
      "train: epoch- 1 loss- 0.25434309244155884\n",
      "train: epoch- 1 loss- 0.2128240466117859\n",
      "train: epoch- 1 loss- 0.12907101213932037\n",
      "train: epoch- 1 loss- 0.1646568328142166\n",
      "train: epoch- 1 loss- 0.1917354166507721\n",
      "train: epoch- 1 loss- 0.2358488291501999\n",
      "train: epoch- 1 loss- 0.17962627112865448\n",
      "train: epoch- 1 loss- 0.302434504032135\n",
      "train: epoch- 1 loss- 0.20508559048175812\n",
      "train: epoch- 1 loss- 0.25474032759666443\n",
      "train: epoch- 1 loss- 0.20611532032489777\n",
      "train: epoch- 1 loss- 0.19276799261569977\n",
      "train: epoch- 1 loss- 0.2291727066040039\n",
      "train: epoch- 1 loss- 0.2770158052444458\n",
      "train: epoch- 1 loss- 0.22532284259796143\n",
      "train: epoch- 1 loss- 0.14113661646842957\n",
      "train: epoch- 1 loss- 0.16359157860279083\n",
      "train: epoch- 1 loss- 0.19409291446208954\n",
      "train: epoch- 1 loss- 0.150680810213089\n",
      "train: epoch- 1 loss- 0.19403764605522156\n",
      "train: epoch- 1 loss- 0.21248643100261688\n",
      "train: epoch- 1 loss- 0.1777893453836441\n",
      "train: epoch- 1 loss- 0.22088894248008728\n",
      "train: epoch- 1 loss- 0.1522229015827179\n",
      "train: epoch- 1 loss- 0.18079160153865814\n",
      "train: epoch- 1 loss- 0.17088226974010468\n",
      "train: epoch- 1 loss- 0.2315790206193924\n",
      "train: epoch- 1 loss- 0.16278855502605438\n",
      "train: epoch- 1 loss- 0.16610226035118103\n",
      "train: epoch- 1 loss- 0.15416549146175385\n",
      "train: epoch- 1 loss- 0.13486720621585846\n",
      "train: epoch- 1 loss- 0.2220318466424942\n",
      "train: epoch- 1 loss- 0.15342141687870026\n",
      "train: epoch- 1 loss- 0.18521995842456818\n",
      "train: epoch- 1 loss- 0.2906710207462311\n",
      "train: epoch- 1 loss- 0.3457547724246979\n",
      "train: epoch- 1 loss- 0.22793391346931458\n",
      "train: epoch- 1 loss- 0.4087989032268524\n",
      "train: epoch- 1 loss- 0.2386753112077713\n",
      "train: epoch- 1 loss- 0.14180611073970795\n",
      "train: epoch- 1 loss- 0.26959484815597534\n",
      "train: epoch- 1 loss- 0.2136794626712799\n",
      "train: epoch- 1 loss- 0.13837933540344238\n",
      "train: epoch- 1 loss- 0.28060096502304077\n",
      "train: epoch- 1 loss- 0.19412121176719666\n",
      "train: epoch- 1 loss- 0.07668719440698624\n",
      "train: epoch- 1 loss- 0.1360546499490738\n",
      "train: epoch- 1 loss- 0.10879658162593842\n",
      "train: epoch- 1 loss- 0.1145963966846466\n",
      "train: epoch- 1 loss- 0.15232810378074646\n",
      "train: epoch- 1 loss- 0.22968049347400665\n",
      "train: epoch- 1 loss- 0.1898079812526703\n",
      "train: epoch- 1 loss- 0.1879255175590515\n",
      "train: epoch- 1 loss- 0.13496726751327515\n",
      "train: epoch- 1 loss- 0.1528618037700653\n",
      "train: epoch- 1 loss- 0.1018105298280716\n",
      "train: epoch- 1 loss- 0.1767570674419403\n",
      "train: epoch- 1 loss- 0.1794273853302002\n",
      "train: epoch- 1 loss- 0.22512148320674896\n",
      "train: epoch- 1 loss- 0.2206261157989502\n",
      "train: epoch- 1 loss- 0.24300388991832733\n",
      "train: epoch- 1 loss- 0.23261426389217377\n",
      "train: epoch- 1 loss- 0.08056658506393433\n",
      "train: epoch- 1 loss- 0.1768849939107895\n",
      "train: epoch- 1 loss- 0.1619773954153061\n",
      "train: epoch- 1 loss- 0.21969814598560333\n",
      "train: epoch- 1 loss- 0.1508820503950119\n",
      "train: epoch- 1 loss- 0.11031512916088104\n",
      "train: epoch- 1 loss- 0.10442303121089935\n",
      "train: epoch- 1 loss- 0.18402016162872314\n",
      "train: epoch- 1 loss- 0.1947377622127533\n",
      "train: epoch- 1 loss- 0.11444241553544998\n",
      "train: epoch- 1 loss- 0.22134317457675934\n",
      "train: epoch- 1 loss- 0.13237611949443817\n",
      "train: epoch- 1 loss- 0.17281636595726013\n",
      "train: epoch- 1 loss- 0.1546943485736847\n",
      "train: epoch- 1 loss- 0.21182182431221008\n",
      "train: epoch- 1 loss- 0.12112285196781158\n",
      "train: epoch- 1 loss- 0.150910884141922\n",
      "train: epoch- 1 loss- 0.14988143742084503\n",
      "train: epoch- 1 loss- 0.11974754929542542\n",
      "train: epoch- 1 loss- 0.17978957295417786\n",
      "train: epoch- 1 loss- 0.23576657474040985\n",
      "train: epoch- 1 loss- 0.11388329416513443\n",
      "train: epoch- 1 loss- 0.1026839017868042\n",
      "train: epoch- 1 loss- 0.1439114809036255\n",
      "train: epoch- 1 loss- 0.13416887819766998\n",
      "train: epoch- 1 loss- 0.09692148864269257\n",
      "train: epoch- 1 loss- 0.21240149438381195\n",
      "train: epoch- 1 loss- 0.20455394685268402\n",
      "train: epoch- 1 loss- 0.3685210943222046\n",
      "train: epoch- 1 loss- 0.1571507751941681\n",
      "train: epoch- 1 loss- 0.2621877193450928\n",
      "train: epoch- 1 loss- 0.1529771387577057\n",
      "train: epoch- 1 loss- 0.16566671431064606\n",
      "train: epoch- 1 loss- 0.1402643620967865\n",
      "train: epoch- 1 loss- 0.21702265739440918\n",
      "train: epoch- 1 loss- 0.12789535522460938\n",
      "train: epoch- 1 loss- 0.18371033668518066\n",
      "train: epoch- 1 loss- 0.12312183529138565\n",
      "train: epoch- 1 loss- 0.16885066032409668\n",
      "train: epoch- 1 loss- 0.2452700287103653\n",
      "train: epoch- 1 loss- 0.14984039962291718\n",
      "train: epoch- 1 loss- 0.13192225992679596\n",
      "train: epoch- 1 loss- 0.31854990124702454\n",
      "train: epoch- 1 loss- 0.10422758758068085\n",
      "train: epoch- 1 loss- 0.14003083109855652\n",
      "train: epoch- 1 loss- 0.11876703798770905\n",
      "train: epoch- 1 loss- 0.10414993017911911\n",
      "train: epoch- 1 loss- 0.0961708277463913\n",
      "train: epoch- 1 loss- 0.11779312044382095\n",
      "train: epoch- 1 loss- 0.1440349519252777\n",
      "train: epoch- 1 loss- 0.1387334167957306\n",
      "train: epoch- 1 loss- 0.15287458896636963\n",
      "train: epoch- 1 loss- 0.1356390416622162\n",
      "train: epoch- 1 loss- 0.08606912940740585\n",
      "train: epoch- 1 loss- 0.26416346430778503\n",
      "train: epoch- 1 loss- 0.13386794924736023\n",
      "train: epoch- 1 loss- 0.10715707391500473\n",
      "train: epoch- 1 loss- 0.29203617572784424\n",
      "train: epoch- 1 loss- 0.18471495807170868\n",
      "train: epoch- 1 loss- 0.15585482120513916\n",
      "train: epoch- 1 loss- 0.14526715874671936\n",
      "train: epoch- 1 loss- 0.24891385436058044\n",
      "train: epoch- 1 loss- 0.14495515823364258\n",
      "train: epoch- 1 loss- 0.3024955689907074\n",
      "train: epoch- 1 loss- 0.16147151589393616\n",
      "train: epoch- 1 loss- 0.15205511450767517\n",
      "train: epoch- 1 loss- 0.17511887848377228\n",
      "train: epoch- 1 loss- 0.125774547457695\n",
      "train: epoch- 1 loss- 0.21306012570858002\n",
      "train: epoch- 1 loss- 0.12412022054195404\n",
      "train: epoch- 1 loss- 0.13218164443969727\n",
      "train: epoch- 1 loss- 0.18379805982112885\n",
      "train: epoch- 1 loss- 0.17883609235286713\n",
      "train: epoch- 1 loss- 0.17164883017539978\n",
      "train: epoch- 1 loss- 0.14416731894016266\n",
      "train: epoch- 1 loss- 0.19315330684185028\n",
      "train: epoch- 1 loss- 0.18918411433696747\n",
      "train: epoch- 1 loss- 0.08688435703516006\n",
      "train: epoch- 1 loss- 0.13013625144958496\n",
      "train: epoch- 1 loss- 0.12045008689165115\n",
      "train: epoch- 1 loss- 0.20436425507068634\n",
      "train: epoch- 1 loss- 0.16401268541812897\n",
      "train: epoch- 1 loss- 0.20664964616298676\n",
      "train: epoch- 1 loss- 0.1056855320930481\n",
      "train: epoch- 1 loss- 0.18616245687007904\n",
      "train: epoch- 1 loss- 0.11628387868404388\n",
      "train: epoch- 1 loss- 0.1374565213918686\n",
      "train: epoch- 1 loss- 0.08143392950296402\n",
      "train: epoch- 1 loss- 0.19163748621940613\n",
      "train: epoch- 1 loss- 0.1227525994181633\n",
      "train: epoch- 1 loss- 0.20023882389068604\n",
      "train: epoch- 1 loss- 0.22428841888904572\n",
      "train: epoch- 1 loss- 0.17071598768234253\n",
      "train: epoch- 1 loss- 0.1549926996231079\n",
      "train: epoch- 1 loss- 0.1482985019683838\n",
      "train: epoch- 1 loss- 0.31482332944869995\n",
      "train: epoch- 1 loss- 0.26211604475975037\n",
      "train: epoch- 1 loss- 0.10253460705280304\n",
      "train: epoch- 1 loss- 0.081937275826931\n",
      "train: epoch- 1 loss- 0.13356932997703552\n",
      "train: epoch- 1 loss- 0.23698700964450836\n",
      "train: epoch- 1 loss- 0.2018246054649353\n",
      "train: epoch- 1 loss- 0.11201347410678864\n",
      "train: epoch- 1 loss- 0.14542526006698608\n",
      "train: epoch- 1 loss- 0.12331752479076385\n",
      "train: epoch- 1 loss- 0.14863352477550507\n",
      "train: epoch- 1 loss- 0.14282844960689545\n",
      "train: epoch- 1 loss- 0.09981284290552139\n",
      "train: epoch- 1 loss- 0.22120846807956696\n",
      "train: epoch- 1 loss- 0.12059951573610306\n",
      "train: epoch- 1 loss- 0.12024664133787155\n",
      "train: epoch- 1 loss- 0.20534002780914307\n",
      "train: epoch- 1 loss- 0.13234829902648926\n",
      "train: epoch- 1 loss- 0.16696608066558838\n",
      "train: epoch- 1 loss- 0.3075152337551117\n",
      "train: epoch- 1 loss- 0.1312790811061859\n",
      "train: epoch- 1 loss- 0.20460902154445648\n",
      "train: epoch- 1 loss- 0.16329336166381836\n",
      "train: epoch- 1 loss- 0.21944354474544525\n",
      "train: epoch- 1 loss- 0.0738176554441452\n",
      "train: epoch- 1 loss- 0.15741361677646637\n",
      "train: epoch- 1 loss- 0.10968448966741562\n",
      "train: epoch- 1 loss- 0.19380781054496765\n",
      "train: epoch- 1 loss- 0.1273597627878189\n",
      "train: epoch- 1 loss- 0.09917020052671432\n",
      "train: epoch- 1 loss- 0.12087707966566086\n",
      "train: epoch- 1 loss- 0.18270616233348846\n",
      "train: epoch- 1 loss- 0.13836048543453217\n",
      "train: epoch- 1 loss- 0.13090743124485016\n",
      "train: epoch- 1 loss- 0.2100028097629547\n",
      "train: epoch- 1 loss- 0.14733357727527618\n",
      "train: epoch- 1 loss- 0.10955453664064407\n",
      "train: epoch- 1 loss- 0.2812937796115875\n",
      "train: epoch- 1 loss- 0.0913504809141159\n",
      "train: epoch- 1 loss- 0.08822900056838989\n",
      "train: epoch- 1 loss- 0.10320694744586945\n",
      "train: epoch- 1 loss- 0.11515465378761292\n",
      "train: epoch- 1 loss- 0.10735255479812622\n",
      "train: epoch- 1 loss- 0.17270877957344055\n",
      "train: epoch- 1 loss- 0.08689762651920319\n",
      "train: epoch- 1 loss- 0.15406565368175507\n",
      "train: epoch- 1 loss- 0.18778325617313385\n",
      "train: epoch- 1 loss- 0.1410566121339798\n",
      "train: epoch- 1 loss- 0.22535055875778198\n",
      "train: epoch- 1 loss- 0.13776996731758118\n",
      "train: epoch- 1 loss- 0.14679019153118134\n",
      "train: epoch- 1 loss- 0.1519431322813034\n",
      "train: epoch- 1 loss- 0.12990066409111023\n",
      "train: epoch- 1 loss- 0.12900389730930328\n",
      "train: epoch- 1 loss- 0.11441005766391754\n",
      "train: epoch- 1 loss- 0.20700962841510773\n",
      "train: epoch- 1 loss- 0.12881971895694733\n",
      "train: epoch- 1 loss- 0.145915687084198\n",
      "train: epoch- 1 loss- 0.20279031991958618\n",
      "train: epoch- 1 loss- 0.20091989636421204\n",
      "train: epoch- 1 loss- 0.1596231609582901\n",
      "train: epoch- 1 loss- 0.09535914659500122\n",
      "train: epoch- 1 loss- 0.14634227752685547\n",
      "train: epoch- 1 loss- 0.2536058723926544\n",
      "train: epoch- 1 loss- 0.1360703408718109\n",
      "train: epoch- 1 loss- 0.22393828630447388\n",
      "train: epoch- 1 loss- 0.24178293347358704\n",
      "train: epoch- 1 loss- 0.17413873970508575\n",
      "train: epoch- 1 loss- 0.1642007827758789\n",
      "train: epoch- 1 loss- 0.09041231125593185\n",
      "train: epoch- 1 loss- 0.10817601531744003\n",
      "train: epoch- 1 loss- 0.19110524654388428\n",
      "train: epoch- 1 loss- 0.13720473647117615\n",
      "train: epoch- 1 loss- 0.12642113864421844\n",
      "train: epoch- 1 loss- 0.11172498017549515\n",
      "train: epoch- 1 loss- 0.11371497064828873\n",
      "train: epoch- 1 loss- 0.12972158193588257\n",
      "train: epoch- 1 loss- 0.13338147103786469\n",
      "train: epoch- 1 loss- 0.11937712877988815\n",
      "train: epoch- 1 loss- 0.11972885578870773\n",
      "train: epoch- 1 loss- 0.1695975512266159\n",
      "train: epoch- 1 loss- 0.11198794841766357\n",
      "train: epoch- 1 loss- 0.11645576357841492\n",
      "train: epoch- 1 loss- 0.27569591999053955\n",
      "train: epoch- 1 loss- 0.06890130043029785\n",
      "train: epoch- 1 loss- 0.18625150620937347\n",
      "train: epoch- 1 loss- 0.12920165061950684\n",
      "train: epoch- 1 loss- 0.1046043187379837\n",
      "train: epoch- 1 loss- 0.09603355079889297\n",
      "train: epoch- 1 loss- 0.21214716136455536\n",
      "train: epoch- 1 loss- 0.22983631491661072\n",
      "train: epoch- 1 loss- 0.08344954252243042\n",
      "train: epoch- 1 loss- 0.17989280819892883\n",
      "train: epoch- 1 loss- 0.17235375940799713\n",
      "train: epoch- 1 loss- 0.07868826389312744\n",
      "train: epoch- 1 loss- 0.132071852684021\n",
      "train: epoch- 1 loss- 0.2620745003223419\n",
      "train: epoch- 1 loss- 0.13619819283485413\n",
      "train: epoch- 1 loss- 0.2234165519475937\n",
      "train: epoch- 1 loss- 0.20966824889183044\n",
      "train: epoch- 1 loss- 0.1074434146285057\n",
      "train: epoch- 1 loss- 0.10994541645050049\n",
      "train: epoch- 1 loss- 0.15327613055706024\n",
      "train: epoch- 1 loss- 0.17135049402713776\n",
      "train: epoch- 1 loss- 0.11356301605701447\n",
      "train: epoch- 1 loss- 0.1537678986787796\n",
      "train: epoch- 1 loss- 0.1311284899711609\n",
      "train: epoch- 1 loss- 0.08742201328277588\n",
      "train: epoch- 1 loss- 0.10247433930635452\n",
      "train: epoch- 1 loss- 0.26848798990249634\n",
      "train: epoch- 1 loss- 0.1384616643190384\n",
      "train: epoch- 1 loss- 0.144693061709404\n",
      "train: epoch- 1 loss- 0.10589227080345154\n",
      "train: epoch- 1 loss- 0.11338961869478226\n",
      "train: epoch- 1 loss- 0.14591819047927856\n",
      "train: epoch- 1 loss- 0.10471821576356888\n",
      "train: epoch- 1 loss- 0.0420222245156765\n",
      "train: epoch- 1 loss- 0.10631653666496277\n",
      "train: epoch- 1 loss- 0.24280425906181335\n",
      "train: epoch- 1 loss- 0.08575370907783508\n",
      "train: epoch- 1 loss- 0.1170942410826683\n",
      "train: epoch- 1 loss- 0.08944312483072281\n",
      "train: epoch- 1 loss- 0.18526095151901245\n",
      "train: epoch- 1 loss- 0.2698397636413574\n",
      "train: epoch- 1 loss- 0.1616310328245163\n",
      "train: epoch- 1 loss- 0.08227644115686417\n",
      "train: epoch- 1 loss- 0.1321156769990921\n",
      "train: epoch- 1 loss- 0.1618395894765854\n",
      "train: epoch- 1 loss- 0.10004805773496628\n",
      "train: epoch- 1 loss- 0.15444795787334442\n",
      "train: epoch- 1 loss- 0.12806254625320435\n",
      "train: epoch- 1 loss- 0.1732410341501236\n",
      "train: epoch- 1 loss- 0.10176047682762146\n",
      "train: epoch- 1 loss- 0.1289970427751541\n",
      "train: epoch- 1 loss- 0.1600685566663742\n",
      "train: epoch- 1 loss- 0.2150871455669403\n",
      "train: epoch- 1 loss- 0.15406237542629242\n",
      "train: epoch- 1 loss- 0.12125353515148163\n",
      "train: epoch- 1 loss- 0.0728340744972229\n",
      "train: epoch- 1 loss- 0.14406847953796387\n",
      "train: epoch- 1 loss- 0.1035616472363472\n",
      "train: epoch- 1 loss- 0.18138164281845093\n",
      "train: epoch- 1 loss- 0.07339057326316833\n",
      "train: epoch- 1 loss- 0.08074714243412018\n",
      "train: epoch- 1 loss- 0.13081789016723633\n",
      "train: epoch- 1 loss- 0.08566463738679886\n",
      "train: epoch- 1 loss- 0.08405463397502899\n",
      "train: epoch- 1 loss- 0.17020107805728912\n",
      "train: epoch- 1 loss- 0.12063416093587875\n",
      "train: epoch- 1 loss- 0.04862295836210251\n",
      "train: epoch- 1 loss- 0.08879344165325165\n",
      "train: epoch- 1 loss- 0.07989776134490967\n",
      "train: epoch- 1 loss- 0.2015450894832611\n",
      "train: epoch- 1 loss- 0.0661887526512146\n",
      "train: epoch- 1 loss- 0.07836106419563293\n",
      "train: epoch- 1 loss- 0.1165146678686142\n",
      "train: epoch- 1 loss- 0.1181984469294548\n",
      "train: epoch- 1 loss- 0.20989485085010529\n",
      "train: epoch- 1 loss- 0.12390130013227463\n",
      "train: epoch- 1 loss- 0.16652211546897888\n",
      "train: epoch- 1 loss- 0.20561830699443817\n",
      "train: epoch- 1 loss- 0.07481715828180313\n",
      "train: epoch- 1 loss- 0.21359147131443024\n",
      "train: epoch- 1 loss- 0.17951634526252747\n",
      "train: epoch- 1 loss- 0.11669443547725677\n",
      "train: epoch- 1 loss- 0.25544726848602295\n",
      "train: epoch- 1 loss- 0.2136380523443222\n",
      "train: epoch- 1 loss- 0.1387602984905243\n",
      "train: epoch- 1 loss- 0.2574465870857239\n",
      "train: epoch- 1 loss- 0.09916751086711884\n",
      "train: epoch- 1 loss- 0.10472049564123154\n",
      "train: epoch- 1 loss- 0.30933117866516113\n",
      "train: epoch- 1 loss- 0.15521636605262756\n",
      "train: epoch- 1 loss- 0.17336903512477875\n",
      "train: epoch- 1 loss- 0.12022406607866287\n",
      "train: epoch- 1 loss- 0.07816145569086075\n",
      "train: epoch- 1 loss- 0.20433084666728973\n",
      "train: epoch- 1 loss- 0.11300785094499588\n",
      "train: epoch- 1 loss- 0.11996235698461533\n",
      "train: epoch- 1 loss- 0.1460433155298233\n",
      "train: epoch- 1 loss- 0.07159139215946198\n",
      "train: epoch- 1 loss- 0.08960460871458054\n",
      "train: epoch- 1 loss- 0.2094782590866089\n",
      "train: epoch- 1 loss- 0.14986105263233185\n",
      "train: epoch- 1 loss- 0.23672431707382202\n",
      "train: epoch- 1 loss- 0.19182924926280975\n",
      "epoch 1: acc = 0.9597\n",
      "train: epoch- 2 loss- 0.12214647978544235\n",
      "train: epoch- 2 loss- 0.14067339897155762\n",
      "train: epoch- 2 loss- 0.2423298954963684\n",
      "train: epoch- 2 loss- 0.19089597463607788\n",
      "train: epoch- 2 loss- 0.12730473279953003\n",
      "train: epoch- 2 loss- 0.32185399532318115\n",
      "train: epoch- 2 loss- 0.10394279658794403\n",
      "train: epoch- 2 loss- 0.21080604195594788\n",
      "train: epoch- 2 loss- 0.08056947588920593\n",
      "train: epoch- 2 loss- 0.1837509423494339\n",
      "train: epoch- 2 loss- 0.079290971159935\n",
      "train: epoch- 2 loss- 0.21155427396297455\n",
      "train: epoch- 2 loss- 0.11146137863397598\n",
      "train: epoch- 2 loss- 0.1888463795185089\n",
      "train: epoch- 2 loss- 0.13468556106090546\n",
      "train: epoch- 2 loss- 0.1592971533536911\n",
      "train: epoch- 2 loss- 0.13894814252853394\n",
      "train: epoch- 2 loss- 0.07561206072568893\n",
      "train: epoch- 2 loss- 0.116981141269207\n",
      "train: epoch- 2 loss- 0.11396884173154831\n",
      "train: epoch- 2 loss- 0.13694220781326294\n",
      "train: epoch- 2 loss- 0.1482965350151062\n",
      "train: epoch- 2 loss- 0.28189343214035034\n",
      "train: epoch- 2 loss- 0.0760532021522522\n",
      "train: epoch- 2 loss- 0.10451987385749817\n",
      "train: epoch- 2 loss- 0.3163881003856659\n",
      "train: epoch- 2 loss- 0.16225802898406982\n",
      "train: epoch- 2 loss- 0.1986164003610611\n",
      "train: epoch- 2 loss- 0.09123976528644562\n",
      "train: epoch- 2 loss- 0.0771094262599945\n",
      "train: epoch- 2 loss- 0.12221626937389374\n",
      "train: epoch- 2 loss- 0.16441026329994202\n",
      "train: epoch- 2 loss- 0.09333362430334091\n",
      "train: epoch- 2 loss- 0.1520543098449707\n",
      "train: epoch- 2 loss- 0.1919039785861969\n",
      "train: epoch- 2 loss- 0.14389081299304962\n",
      "train: epoch- 2 loss- 0.12895746529102325\n",
      "train: epoch- 2 loss- 0.09633971750736237\n",
      "train: epoch- 2 loss- 0.16353271901607513\n",
      "train: epoch- 2 loss- 0.04190664365887642\n",
      "train: epoch- 2 loss- 0.20585086941719055\n",
      "train: epoch- 2 loss- 0.13932952284812927\n",
      "train: epoch- 2 loss- 0.17270265519618988\n",
      "train: epoch- 2 loss- 0.12941405177116394\n",
      "train: epoch- 2 loss- 0.11481467634439468\n",
      "train: epoch- 2 loss- 0.1985083669424057\n",
      "train: epoch- 2 loss- 0.12661606073379517\n",
      "train: epoch- 2 loss- 0.13982655107975006\n",
      "train: epoch- 2 loss- 0.1456182301044464\n",
      "train: epoch- 2 loss- 0.22102737426757812\n",
      "train: epoch- 2 loss- 0.1469668298959732\n",
      "train: epoch- 2 loss- 0.18702559173107147\n",
      "train: epoch- 2 loss- 0.14855647087097168\n",
      "train: epoch- 2 loss- 0.08649430423974991\n",
      "train: epoch- 2 loss- 0.13165323436260223\n",
      "train: epoch- 2 loss- 0.19806627929210663\n",
      "train: epoch- 2 loss- 0.09170474112033844\n",
      "train: epoch- 2 loss- 0.14540676772594452\n",
      "train: epoch- 2 loss- 0.15557155013084412\n",
      "train: epoch- 2 loss- 0.11485220491886139\n",
      "train: epoch- 2 loss- 0.0353579968214035\n",
      "train: epoch- 2 loss- 0.09667970985174179\n",
      "train: epoch- 2 loss- 0.13969850540161133\n",
      "train: epoch- 2 loss- 0.08378389477729797\n",
      "train: epoch- 2 loss- 0.15899236500263214\n",
      "train: epoch- 2 loss- 0.21058177947998047\n",
      "train: epoch- 2 loss- 0.12320727854967117\n",
      "train: epoch- 2 loss- 0.062254197895526886\n",
      "train: epoch- 2 loss- 0.07817427068948746\n",
      "train: epoch- 2 loss- 0.12691088020801544\n",
      "train: epoch- 2 loss- 0.09088841080665588\n",
      "train: epoch- 2 loss- 0.11912544816732407\n",
      "train: epoch- 2 loss- 0.0896061435341835\n",
      "train: epoch- 2 loss- 0.06384176015853882\n",
      "train: epoch- 2 loss- 0.1883671134710312\n",
      "train: epoch- 2 loss- 0.19948217272758484\n",
      "train: epoch- 2 loss- 0.13813313841819763\n",
      "train: epoch- 2 loss- 0.12337174266576767\n",
      "train: epoch- 2 loss- 0.08373171836137772\n",
      "train: epoch- 2 loss- 0.15502089262008667\n",
      "train: epoch- 2 loss- 0.1265275627374649\n",
      "train: epoch- 2 loss- 0.1380707323551178\n",
      "train: epoch- 2 loss- 0.1313977688550949\n",
      "train: epoch- 2 loss- 0.07614421844482422\n",
      "train: epoch- 2 loss- 0.14209584891796112\n",
      "train: epoch- 2 loss- 0.14398892223834991\n",
      "train: epoch- 2 loss- 0.1815597414970398\n",
      "train: epoch- 2 loss- 0.20331212878227234\n",
      "train: epoch- 2 loss- 0.1677042692899704\n",
      "train: epoch- 2 loss- 0.14000658690929413\n",
      "train: epoch- 2 loss- 0.16215842962265015\n",
      "train: epoch- 2 loss- 0.09066157042980194\n",
      "train: epoch- 2 loss- 0.18763956427574158\n",
      "train: epoch- 2 loss- 0.13491767644882202\n",
      "train: epoch- 2 loss- 0.12232539802789688\n",
      "train: epoch- 2 loss- 0.10163500905036926\n",
      "train: epoch- 2 loss- 0.1065954640507698\n",
      "train: epoch- 2 loss- 0.10477876663208008\n",
      "train: epoch- 2 loss- 0.1209033727645874\n",
      "train: epoch- 2 loss- 0.12685202062129974\n",
      "train: epoch- 2 loss- 0.044580020010471344\n",
      "train: epoch- 2 loss- 0.11268669366836548\n",
      "train: epoch- 2 loss- 0.10045839846134186\n",
      "train: epoch- 2 loss- 0.1433502435684204\n",
      "train: epoch- 2 loss- 0.24614231288433075\n",
      "train: epoch- 2 loss- 0.11068250238895416\n",
      "train: epoch- 2 loss- 0.16605781018733978\n",
      "train: epoch- 2 loss- 0.16125939786434174\n",
      "train: epoch- 2 loss- 0.16019409894943237\n",
      "train: epoch- 2 loss- 0.1328400820493698\n",
      "train: epoch- 2 loss- 0.14728865027427673\n",
      "train: epoch- 2 loss- 0.15403178334236145\n",
      "train: epoch- 2 loss- 0.08477850258350372\n",
      "train: epoch- 2 loss- 0.19778190553188324\n",
      "train: epoch- 2 loss- 0.22060085833072662\n",
      "train: epoch- 2 loss- 0.03744746744632721\n",
      "train: epoch- 2 loss- 0.15827925503253937\n",
      "train: epoch- 2 loss- 0.14718905091285706\n",
      "train: epoch- 2 loss- 0.17162325978279114\n",
      "train: epoch- 2 loss- 0.11193148046731949\n",
      "train: epoch- 2 loss- 0.12172461301088333\n",
      "train: epoch- 2 loss- 0.22431166470050812\n",
      "train: epoch- 2 loss- 0.1422710418701172\n",
      "train: epoch- 2 loss- 0.14769595861434937\n",
      "train: epoch- 2 loss- 0.17188142240047455\n",
      "train: epoch- 2 loss- 0.08797870576381683\n",
      "train: epoch- 2 loss- 0.12242364138364792\n",
      "train: epoch- 2 loss- 0.161489337682724\n",
      "train: epoch- 2 loss- 0.13331347703933716\n",
      "train: epoch- 2 loss- 0.1252852976322174\n",
      "train: epoch- 2 loss- 0.12040840089321136\n",
      "train: epoch- 2 loss- 0.048954252153635025\n",
      "train: epoch- 2 loss- 0.16358287632465363\n",
      "train: epoch- 2 loss- 0.07864145934581757\n",
      "train: epoch- 2 loss- 0.16367249190807343\n",
      "train: epoch- 2 loss- 0.1171598881483078\n",
      "train: epoch- 2 loss- 0.09296771883964539\n",
      "train: epoch- 2 loss- 0.12025587260723114\n",
      "train: epoch- 2 loss- 0.1755778193473816\n",
      "train: epoch- 2 loss- 0.1352812796831131\n",
      "train: epoch- 2 loss- 0.1846710443496704\n",
      "train: epoch- 2 loss- 0.131461501121521\n",
      "train: epoch- 2 loss- 0.10234727710485458\n",
      "train: epoch- 2 loss- 0.12312261760234833\n",
      "train: epoch- 2 loss- 0.13780945539474487\n",
      "train: epoch- 2 loss- 0.19772247970104218\n",
      "train: epoch- 2 loss- 0.05892105773091316\n",
      "train: epoch- 2 loss- 0.06681957095861435\n",
      "train: epoch- 2 loss- 0.06041746959090233\n",
      "train: epoch- 2 loss- 0.15270106494426727\n",
      "train: epoch- 2 loss- 0.15732665359973907\n",
      "train: epoch- 2 loss- 0.055783141404390335\n",
      "train: epoch- 2 loss- 0.09779180586338043\n",
      "train: epoch- 2 loss- 0.11718793958425522\n",
      "train: epoch- 2 loss- 0.15127436816692352\n",
      "train: epoch- 2 loss- 0.17926563322544098\n",
      "train: epoch- 2 loss- 0.08641347289085388\n",
      "train: epoch- 2 loss- 0.08510001003742218\n",
      "train: epoch- 2 loss- 0.10922978818416595\n",
      "train: epoch- 2 loss- 0.13370269536972046\n",
      "train: epoch- 2 loss- 0.18631304800510406\n",
      "train: epoch- 2 loss- 0.17877954244613647\n",
      "train: epoch- 2 loss- 0.09684492647647858\n",
      "train: epoch- 2 loss- 0.18581028282642365\n",
      "train: epoch- 2 loss- 0.24206633865833282\n",
      "train: epoch- 2 loss- 0.12081640958786011\n",
      "train: epoch- 2 loss- 0.19157440960407257\n",
      "train: epoch- 2 loss- 0.15818004310131073\n",
      "train: epoch- 2 loss- 0.05121257156133652\n",
      "train: epoch- 2 loss- 0.10300536453723907\n",
      "train: epoch- 2 loss- 0.09575536102056503\n",
      "train: epoch- 2 loss- 0.06839136779308319\n",
      "train: epoch- 2 loss- 0.1386251002550125\n",
      "train: epoch- 2 loss- 0.07730243355035782\n",
      "train: epoch- 2 loss- 0.11726191639900208\n",
      "train: epoch- 2 loss- 0.14861322939395905\n",
      "train: epoch- 2 loss- 0.11031756550073624\n",
      "train: epoch- 2 loss- 0.182863250374794\n",
      "train: epoch- 2 loss- 0.11077767610549927\n",
      "train: epoch- 2 loss- 0.19584214687347412\n",
      "train: epoch- 2 loss- 0.22434395551681519\n",
      "train: epoch- 2 loss- 0.06206579878926277\n",
      "train: epoch- 2 loss- 0.1430000364780426\n",
      "train: epoch- 2 loss- 0.09421146661043167\n",
      "train: epoch- 2 loss- 0.182742640376091\n",
      "train: epoch- 2 loss- 0.11527964472770691\n",
      "train: epoch- 2 loss- 0.07337811589241028\n",
      "train: epoch- 2 loss- 0.14344389736652374\n",
      "train: epoch- 2 loss- 0.09135594964027405\n",
      "train: epoch- 2 loss- 0.09120934456586838\n",
      "train: epoch- 2 loss- 0.11614043265581131\n",
      "train: epoch- 2 loss- 0.04131330922245979\n",
      "train: epoch- 2 loss- 0.13120287656784058\n",
      "train: epoch- 2 loss- 0.138016477227211\n",
      "train: epoch- 2 loss- 0.08215554803609848\n",
      "train: epoch- 2 loss- 0.11248833686113358\n",
      "train: epoch- 2 loss- 0.1315915584564209\n",
      "train: epoch- 2 loss- 0.19283343851566315\n",
      "train: epoch- 2 loss- 0.07098954170942307\n",
      "train: epoch- 2 loss- 0.14869679510593414\n",
      "train: epoch- 2 loss- 0.06435833126306534\n",
      "train: epoch- 2 loss- 0.16865168511867523\n",
      "train: epoch- 2 loss- 0.11171936243772507\n",
      "train: epoch- 2 loss- 0.15523415803909302\n",
      "train: epoch- 2 loss- 0.0757041722536087\n",
      "train: epoch- 2 loss- 0.2845675051212311\n",
      "train: epoch- 2 loss- 0.09962653368711472\n",
      "train: epoch- 2 loss- 0.1448325663805008\n",
      "train: epoch- 2 loss- 0.08949223160743713\n",
      "train: epoch- 2 loss- 0.21934491395950317\n",
      "train: epoch- 2 loss- 0.0448811873793602\n",
      "train: epoch- 2 loss- 0.1223248615860939\n",
      "train: epoch- 2 loss- 0.10969457775354385\n",
      "train: epoch- 2 loss- 0.08217711001634598\n",
      "train: epoch- 2 loss- 0.06095077469944954\n",
      "train: epoch- 2 loss- 0.07659383118152618\n",
      "train: epoch- 2 loss- 0.0764007717370987\n",
      "train: epoch- 2 loss- 0.05922679603099823\n",
      "train: epoch- 2 loss- 0.06465966999530792\n",
      "train: epoch- 2 loss- 0.0915154293179512\n",
      "train: epoch- 2 loss- 0.14239588379859924\n",
      "train: epoch- 2 loss- 0.14868468046188354\n",
      "train: epoch- 2 loss- 0.1165185272693634\n",
      "train: epoch- 2 loss- 0.15532316267490387\n",
      "train: epoch- 2 loss- 0.10152660310268402\n",
      "train: epoch- 2 loss- 0.048052527010440826\n",
      "train: epoch- 2 loss- 0.16958637535572052\n",
      "train: epoch- 2 loss- 0.08211201429367065\n",
      "train: epoch- 2 loss- 0.08368116617202759\n",
      "train: epoch- 2 loss- 0.10452377051115036\n",
      "train: epoch- 2 loss- 0.1519445925951004\n",
      "train: epoch- 2 loss- 0.14136511087417603\n",
      "train: epoch- 2 loss- 0.13403001427650452\n",
      "train: epoch- 2 loss- 0.06130281463265419\n",
      "train: epoch- 2 loss- 0.09146925061941147\n",
      "train: epoch- 2 loss- 0.15096597373485565\n",
      "train: epoch- 2 loss- 0.11266942322254181\n",
      "train: epoch- 2 loss- 0.12868022918701172\n",
      "train: epoch- 2 loss- 0.09179329127073288\n",
      "train: epoch- 2 loss- 0.14834780991077423\n",
      "train: epoch- 2 loss- 0.0945284515619278\n",
      "train: epoch- 2 loss- 0.07251743227243423\n",
      "train: epoch- 2 loss- 0.11291670054197311\n",
      "train: epoch- 2 loss- 0.08918160945177078\n",
      "train: epoch- 2 loss- 0.1535552740097046\n",
      "train: epoch- 2 loss- 0.07690365612506866\n",
      "train: epoch- 2 loss- 0.1045515388250351\n",
      "train: epoch- 2 loss- 0.07490212470293045\n",
      "train: epoch- 2 loss- 0.1779034584760666\n",
      "train: epoch- 2 loss- 0.10673888027667999\n",
      "train: epoch- 2 loss- 0.12006580829620361\n",
      "train: epoch- 2 loss- 0.08595187216997147\n",
      "train: epoch- 2 loss- 0.10746370255947113\n",
      "train: epoch- 2 loss- 0.11040482670068741\n",
      "train: epoch- 2 loss- 0.09427530318498611\n",
      "train: epoch- 2 loss- 0.2539500594139099\n",
      "train: epoch- 2 loss- 0.08579850196838379\n",
      "train: epoch- 2 loss- 0.12443514168262482\n",
      "train: epoch- 2 loss- 0.0893109142780304\n",
      "train: epoch- 2 loss- 0.1137913390994072\n",
      "train: epoch- 2 loss- 0.14790715277194977\n",
      "train: epoch- 2 loss- 0.10903673619031906\n",
      "train: epoch- 2 loss- 0.15182732045650482\n",
      "train: epoch- 2 loss- 0.12271091341972351\n",
      "train: epoch- 2 loss- 0.14418531954288483\n",
      "train: epoch- 2 loss- 0.130695641040802\n",
      "train: epoch- 2 loss- 0.12989294528961182\n",
      "train: epoch- 2 loss- 0.08362945169210434\n",
      "train: epoch- 2 loss- 0.06704065948724747\n",
      "train: epoch- 2 loss- 0.14521346986293793\n",
      "train: epoch- 2 loss- 0.18115130066871643\n",
      "train: epoch- 2 loss- 0.05925891175866127\n",
      "train: epoch- 2 loss- 0.10144086927175522\n",
      "train: epoch- 2 loss- 0.0849451869726181\n",
      "train: epoch- 2 loss- 0.14390063285827637\n",
      "train: epoch- 2 loss- 0.13091811537742615\n",
      "train: epoch- 2 loss- 0.1280512809753418\n",
      "train: epoch- 2 loss- 0.10104120522737503\n",
      "train: epoch- 2 loss- 0.12507836520671844\n",
      "train: epoch- 2 loss- 0.07383539527654648\n",
      "train: epoch- 2 loss- 0.14673341810703278\n",
      "train: epoch- 2 loss- 0.16252566874027252\n",
      "train: epoch- 2 loss- 0.0881306380033493\n",
      "train: epoch- 2 loss- 0.12744829058647156\n",
      "train: epoch- 2 loss- 0.08432507514953613\n",
      "train: epoch- 2 loss- 0.06274177134037018\n",
      "train: epoch- 2 loss- 0.10421842336654663\n",
      "train: epoch- 2 loss- 0.1115032210946083\n",
      "train: epoch- 2 loss- 0.1701439917087555\n",
      "train: epoch- 2 loss- 0.1111639142036438\n",
      "train: epoch- 2 loss- 0.11378104984760284\n",
      "train: epoch- 2 loss- 0.16645070910453796\n",
      "train: epoch- 2 loss- 0.1644192934036255\n",
      "train: epoch- 2 loss- 0.19511345028877258\n",
      "train: epoch- 2 loss- 0.14867697656154633\n",
      "train: epoch- 2 loss- 0.1055176705121994\n",
      "train: epoch- 2 loss- 0.1958058923482895\n",
      "train: epoch- 2 loss- 0.13092437386512756\n",
      "train: epoch- 2 loss- 0.11115389317274094\n",
      "train: epoch- 2 loss- 0.1518528014421463\n",
      "train: epoch- 2 loss- 0.06998976320028305\n",
      "train: epoch- 2 loss- 0.26964429020881653\n",
      "train: epoch- 2 loss- 0.06468970328569412\n",
      "train: epoch- 2 loss- 0.11445804685354233\n",
      "train: epoch- 2 loss- 0.05385051667690277\n",
      "train: epoch- 2 loss- 0.09070827811956406\n",
      "train: epoch- 2 loss- 0.15245996415615082\n",
      "train: epoch- 2 loss- 0.11695174872875214\n",
      "train: epoch- 2 loss- 0.03307890146970749\n",
      "train: epoch- 2 loss- 0.06316336244344711\n",
      "train: epoch- 2 loss- 0.16736261546611786\n",
      "train: epoch- 2 loss- 0.07088131457567215\n",
      "train: epoch- 2 loss- 0.09217845648527145\n",
      "train: epoch- 2 loss- 0.09584885090589523\n",
      "train: epoch- 2 loss- 0.1758098006248474\n",
      "train: epoch- 2 loss- 0.20058606564998627\n",
      "train: epoch- 2 loss- 0.17201152443885803\n",
      "train: epoch- 2 loss- 0.1131766140460968\n",
      "train: epoch- 2 loss- 0.09363826364278793\n",
      "train: epoch- 2 loss- 0.07489047944545746\n",
      "train: epoch- 2 loss- 0.12903591990470886\n",
      "train: epoch- 2 loss- 0.1495869904756546\n",
      "train: epoch- 2 loss- 0.048006556928157806\n",
      "train: epoch- 2 loss- 0.11711146682500839\n",
      "train: epoch- 2 loss- 0.10271431505680084\n",
      "train: epoch- 2 loss- 0.03328115493059158\n",
      "train: epoch- 2 loss- 0.07574504613876343\n",
      "train: epoch- 2 loss- 0.09659598767757416\n",
      "train: epoch- 2 loss- 0.16528917849063873\n",
      "train: epoch- 2 loss- 0.06374654173851013\n",
      "train: epoch- 2 loss- 0.12237696349620819\n",
      "train: epoch- 2 loss- 0.15488101541996002\n",
      "train: epoch- 2 loss- 0.20750148594379425\n",
      "train: epoch- 2 loss- 0.10380780696868896\n",
      "train: epoch- 2 loss- 0.07810820639133453\n",
      "train: epoch- 2 loss- 0.10174858570098877\n",
      "train: epoch- 2 loss- 0.09440924227237701\n",
      "train: epoch- 2 loss- 0.05405552312731743\n",
      "train: epoch- 2 loss- 0.1344572901725769\n",
      "train: epoch- 2 loss- 0.129877507686615\n",
      "train: epoch- 2 loss- 0.1285863220691681\n",
      "train: epoch- 2 loss- 0.11080114543437958\n",
      "train: epoch- 2 loss- 0.13240256905555725\n",
      "train: epoch- 2 loss- 0.11115578562021255\n",
      "train: epoch- 2 loss- 0.11223441362380981\n",
      "train: epoch- 2 loss- 0.09737682342529297\n",
      "train: epoch- 2 loss- 0.14512230455875397\n",
      "train: epoch- 2 loss- 0.1889660805463791\n",
      "train: epoch- 2 loss- 0.18445807695388794\n",
      "train: epoch- 2 loss- 0.05323009192943573\n",
      "train: epoch- 2 loss- 0.10916063189506531\n",
      "train: epoch- 2 loss- 0.049106232821941376\n",
      "train: epoch- 2 loss- 0.08709456771612167\n",
      "train: epoch- 2 loss- 0.08715636283159256\n",
      "train: epoch- 2 loss- 0.12348318845033646\n",
      "train: epoch- 2 loss- 0.2042633295059204\n",
      "train: epoch- 2 loss- 0.07493861764669418\n",
      "train: epoch- 2 loss- 0.17340736091136932\n",
      "train: epoch- 2 loss- 0.13829374313354492\n",
      "train: epoch- 2 loss- 0.06753627210855484\n",
      "train: epoch- 2 loss- 0.20487946271896362\n",
      "train: epoch- 2 loss- 0.03929080441594124\n",
      "train: epoch- 2 loss- 0.2132762223482132\n",
      "train: epoch- 2 loss- 0.18220634758472443\n",
      "train: epoch- 2 loss- 0.12179284542798996\n",
      "train: epoch- 2 loss- 0.18022911250591278\n",
      "train: epoch- 2 loss- 0.13960838317871094\n",
      "train: epoch- 2 loss- 0.15125754475593567\n",
      "train: epoch- 2 loss- 0.08495545387268066\n",
      "train: epoch- 2 loss- 0.10548518598079681\n",
      "train: epoch- 2 loss- 0.10961423814296722\n",
      "train: epoch- 2 loss- 0.0681614801287651\n",
      "train: epoch- 2 loss- 0.046476222574710846\n",
      "train: epoch- 2 loss- 0.10464942455291748\n",
      "train: epoch- 2 loss- 0.23851247131824493\n",
      "train: epoch- 2 loss- 0.23888468742370605\n",
      "train: epoch- 2 loss- 0.1173878088593483\n",
      "train: epoch- 2 loss- 0.09157469123601913\n",
      "train: epoch- 2 loss- 0.13776662945747375\n",
      "train: epoch- 2 loss- 0.0757763534784317\n",
      "train: epoch- 2 loss- 0.1617315262556076\n",
      "train: epoch- 2 loss- 0.1139218658208847\n",
      "train: epoch- 2 loss- 0.0584569089114666\n",
      "train: epoch- 2 loss- 0.06278509646654129\n",
      "train: epoch- 2 loss- 0.16362524032592773\n",
      "train: epoch- 2 loss- 0.18029789626598358\n",
      "train: epoch- 2 loss- 0.09911845624446869\n",
      "train: epoch- 2 loss- 0.10848048329353333\n",
      "train: epoch- 2 loss- 0.136081725358963\n",
      "train: epoch- 2 loss- 0.043390750885009766\n",
      "train: epoch- 2 loss- 0.21073582768440247\n",
      "train: epoch- 2 loss- 0.05495612695813179\n",
      "train: epoch- 2 loss- 0.11135376989841461\n",
      "train: epoch- 2 loss- 0.08757766336202621\n",
      "train: epoch- 2 loss- 0.16975443065166473\n",
      "train: epoch- 2 loss- 0.11188238859176636\n",
      "train: epoch- 2 loss- 0.04971220716834068\n",
      "train: epoch- 2 loss- 0.2245243787765503\n",
      "train: epoch- 2 loss- 0.13655680418014526\n",
      "train: epoch- 2 loss- 0.21120169758796692\n",
      "train: epoch- 2 loss- 0.0608564056456089\n",
      "train: epoch- 2 loss- 0.10196752101182938\n",
      "train: epoch- 2 loss- 0.24916520714759827\n",
      "train: epoch- 2 loss- 0.07126963138580322\n",
      "train: epoch- 2 loss- 0.07690885663032532\n",
      "train: epoch- 2 loss- 0.07546895742416382\n",
      "train: epoch- 2 loss- 0.08581043034791946\n",
      "train: epoch- 2 loss- 0.07720015943050385\n",
      "train: epoch- 2 loss- 0.09064307063817978\n",
      "train: epoch- 2 loss- 0.08200260996818542\n",
      "train: epoch- 2 loss- 0.05655403435230255\n",
      "train: epoch- 2 loss- 0.07699193060398102\n",
      "train: epoch- 2 loss- 0.05065277963876724\n",
      "train: epoch- 2 loss- 0.04920635744929314\n",
      "train: epoch- 2 loss- 0.06759188324213028\n",
      "train: epoch- 2 loss- 0.16567283868789673\n",
      "train: epoch- 2 loss- 0.1378735899925232\n",
      "train: epoch- 2 loss- 0.09742837399244308\n",
      "train: epoch- 2 loss- 0.14177393913269043\n",
      "train: epoch- 2 loss- 0.2049163430929184\n",
      "train: epoch- 2 loss- 0.09173940122127533\n",
      "train: epoch- 2 loss- 0.09851023554801941\n",
      "train: epoch- 2 loss- 0.16054989397525787\n",
      "train: epoch- 2 loss- 0.07856115698814392\n",
      "train: epoch- 2 loss- 0.14780421555042267\n",
      "train: epoch- 2 loss- 0.10249128192663193\n",
      "train: epoch- 2 loss- 0.07449638098478317\n",
      "train: epoch- 2 loss- 0.11581486463546753\n",
      "train: epoch- 2 loss- 0.03971029072999954\n",
      "train: epoch- 2 loss- 0.038529232144355774\n",
      "train: epoch- 2 loss- 0.09590217471122742\n",
      "train: epoch- 2 loss- 0.10642868280410767\n",
      "train: epoch- 2 loss- 0.1290493607521057\n",
      "train: epoch- 2 loss- 0.09235911071300507\n",
      "train: epoch- 2 loss- 0.09298504889011383\n",
      "train: epoch- 2 loss- 0.11660294979810715\n",
      "train: epoch- 2 loss- 0.10497505217790604\n",
      "train: epoch- 2 loss- 0.17422175407409668\n",
      "train: epoch- 2 loss- 0.06239105761051178\n",
      "train: epoch- 2 loss- 0.0704510509967804\n",
      "train: epoch- 2 loss- 0.09522796422243118\n",
      "train: epoch- 2 loss- 0.1409052610397339\n",
      "train: epoch- 2 loss- 0.17197608947753906\n",
      "train: epoch- 2 loss- 0.0911431759595871\n",
      "train: epoch- 2 loss- 0.10083363950252533\n",
      "train: epoch- 2 loss- 0.085719995200634\n",
      "train: epoch- 2 loss- 0.06158120930194855\n",
      "train: epoch- 2 loss- 0.08361145108938217\n",
      "train: epoch- 2 loss- 0.09071805328130722\n",
      "train: epoch- 2 loss- 0.035828374326229095\n",
      "train: epoch- 2 loss- 0.14045514166355133\n",
      "train: epoch- 2 loss- 0.17540688812732697\n",
      "train: epoch- 2 loss- 0.1104707196354866\n",
      "train: epoch- 2 loss- 0.11534769833087921\n",
      "train: epoch- 2 loss- 0.03440309315919876\n",
      "train: epoch- 2 loss- 0.09514952450990677\n",
      "train: epoch- 2 loss- 0.15318219363689423\n",
      "train: epoch- 2 loss- 0.15552562475204468\n",
      "train: epoch- 2 loss- 0.20077787339687347\n",
      "train: epoch- 2 loss- 0.09952518343925476\n",
      "train: epoch- 2 loss- 0.05662940442562103\n",
      "train: epoch- 2 loss- 0.1429995745420456\n",
      "train: epoch- 2 loss- 0.13372009992599487\n",
      "train: epoch- 2 loss- 0.11656789481639862\n",
      "train: epoch- 2 loss- 0.0774041935801506\n",
      "train: epoch- 2 loss- 0.13793733716011047\n",
      "train: epoch- 2 loss- 0.11688835173845291\n",
      "train: epoch- 2 loss- 0.04526987671852112\n",
      "train: epoch- 2 loss- 0.04677756503224373\n",
      "epoch 2: acc = 0.9676\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(3):\n",
    "    model.train()\n",
    "    for x,y in train_loader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(x)\n",
    "        loss = criterion(logits,y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print(f\"train: epoch- {epoch} loss- {loss}\")        \n",
    "    \n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for x,y in test_loader:\n",
    "            preds = model(x).argmax(1)\n",
    "            correct += (preds==y).sum().item()\n",
    "            total += y.size(0)\n",
    "    print(f\"epoch {epoch}: acc = {correct/total}\")\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "44a91ddb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as tinycnn_mnist.pt\n"
     ]
    }
   ],
   "source": [
    "## inference\n",
    "model.eval()\n",
    "example_input = torch.randn(1, 1, 28, 28).to(device)\n",
    "traced_model = torch.jit.trace(model, example_input)\n",
    "traced_model.save(\"tinycnn_mnist.pt\")\n",
    "print(\"Model saved as tinycnn_mnist.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "5b01f7cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded and ready for inference\n"
     ]
    }
   ],
   "source": [
    "loaded_model = torch.jit.load(\"tinycnn_mnist.pt\")\n",
    "loaded_model.to(device)\n",
    "loaded_model.eval()\n",
    "print(\"Model loaded and ready for inference\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "242e522a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: 7\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img, label = test_ds[0]\n",
    "plt.imshow(img.squeeze(), cmap='gray')\n",
    "plt.title(f\"True label: {label}\")\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "x = img.unsqueeze(0).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    logits = loaded_model(x)\n",
    "    pred = logits.argmax(1).item()\n",
    "\n",
    "print(\"Predicted:\", pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ff6d6c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
