××¦×•×™×Ÿ ğŸ™Œ
×× ×™ ××‘× ×” ×œ×š ×¢×›×©×™×• **××¡××š ××¡×•×“×¨**:

* ×œ×›×œ ××©×™××”:

  1. **×”×¡×‘×¨** (××” ×”××©×™××” ×•×œ××” ×”×™× ×—×©×•×‘×”).
  2. **××•×“×œ ××œ× (PyTorch)** â€“ ×¢× ×”×¢×¨×•×ª ×¢×œ **×¦×•×¨×•×ª ×”Ö¾input ×•×”Ö¾output** ×‘×›×œ ×©×œ×‘.
  3. **Loss** ×•×œ××” ×”×•× ××ª××™×.
  4. **××•×“×œ×™× ×’×“×•×œ×™× ××”×¢×•×œ×**.
  5. **×©××œ×•×ª ××§×¦×•×¢×™×•×ª ×©×™×›×•×œ×™× ×œ×©××•×œ ××•×ª×š** ×‘×¨××™×•×Ÿ ×¢×œ ×”××©×™××”.

×× ×™ ×’× ××•×¡×™×£ ×›××” ××©×™××•×ª × ×•×¡×¤×•×ª ××¢×‘×¨ ×œ××” ×©×›×‘×¨ ×›×ª×‘× ×•:

* Classification (×‘×¡×™×¡×™, ×œ×”×©×•×•××”)
* Object Detection
* Semantic Segmentation
* Instance Segmentation
* Depth Estimation
* Optical Flow
* Lane Detection
* Trajectory Prediction
* Anomaly Detection
* Image Captioning (××©×™××” ××•×œ×˜×™××•×“×œ×™×ª)
* Super-Resolution (×©×—×–×•×¨ ×ª××•× ×”)
* Image Inpainting (×”×©×œ××ª ×¤×™×§×¡×œ×™× ×—×¡×¨×™×)

---

# ğŸ”¥ Computer Vision Tasks

---

## 1. **Image Classification**

**×”×¡×‘×¨:** ×”××©×™××” ×”×¤×©×•×˜×” ×‘×™×•×ª×¨ â€“ ×œ×§×‘×œ ×ª××•× ×” ×•×œ×”×—×–×™×¨ label ×™×—×™×“ ×©××ª××¨ ××ª ×”×§×˜×’×•×¨×™×” ×©×œ×”.

```python
import torch
import torch.nn as nn
import torchvision.models as models

# ----- Model -----
class ImageClassifier(nn.Module):
    def __init__(self, num_classes=10):
        super().__init__()
        backbone = models.resnet18(weights=None)
        self.feature_extractor = nn.Sequential(*list(backbone.children())[:-1])  
        # input: [B, 3, 224, 224]
        # output: [B, 512, 1, 1]
        self.fc = nn.Linear(512, num_classes)

    def forward(self, x):
        feats = self.feature_extractor(x)  # [B, 512, 1, 1]
        feats = feats.view(feats.size(0), -1)  # [B, 512]
        out = self.fc(feats)  # [B, num_classes]
        return out
```

```python
# ----- Loss -----
criterion = nn.CrossEntropyLoss()
```

**×œ××” ×”×œ×•×¡ ××ª××™×?**
×›×œ sample ×©×™×™×š ×œ×§×˜×’×•×¨×™×” ××—×ª â†’ CrossEntropyLoss ××ª××™× ×œ×¡×™×•×•×’ ×¨×‘-×§×˜×’×•×¨×™.

**××•×“×œ×™× ×’×“×•×œ×™×:** ResNet, EfficientNet, Vision Transformer.

**×©××œ×•×ª ××§×¦×•×¢×™×•×ª:**

* ××” ×”×”×‘×“×œ ×‘×™×Ÿ Softmax ×œ-Sigmoid ×‘Ö¾output layer?
* ×œ××” ×›×“××™ ×œ×”×©×ª××© ×‘Ö¾pretrained backbone?
* ××™×š ××ª××•×“×“×™× ×¢× dataset ×œ× ×××•×–×Ÿ (class imbalance)?

---

## 2. **Object Detection**

**×”×¡×‘×¨:** ××–×”×” ×’× ××” ×™×© ×‘×ª××•× ×” ×•×’× ××™×¤×” (bounding box).

```python
class SimpleDetector(nn.Module):
    def __init__(self, num_classes=10):
        super().__init__()
        backbone = models.resnet18(weights=None)
        self.features = nn.Sequential(*list(backbone.children())[:-2])  
        # input: [B, 3, 224, 224]
        # output: [B, 512, 7, 7]
        self.cls_head = nn.Linear(512, num_classes)
        self.box_head = nn.Linear(512, 4)

    def forward(self, x):
        feats = self.features(x)  # [B, 512, 7, 7]
        pooled = feats.mean(dim=[2, 3])  # [B, 512]
        cls_logits = self.cls_head(pooled)  # [B, num_classes]
        bbox = self.box_head(pooled)  # [B, 4]
        return cls_logits, bbox
```

```python
# ----- Loss -----
cls_loss = nn.CrossEntropyLoss()
bbox_loss = nn.SmoothL1Loss()
```

**×œ××” ×”×œ×•×¡ ××ª××™×?**

* ×¡×™×•×•×’ â†’ CrossEntropyLoss.
* ×¨×’×¨×¡×™×” ×©×œ ×‘×•×§×¡ â†’ SmoothL1Loss ×¢×“×™×£ ×¢×œ MSE ×›×™ ×¤×—×•×ª ××•×©×¤×¢ ×Ö¾outliers.

**××•×“×œ×™× ×’×“×•×œ×™×:** YOLOv8, Faster R-CNN, DETR.

**×©××œ×•×ª ××§×¦×•×¢×™×•×ª:**

* ×œ××” ×¦×¨×™×š Anchor Boxes?
* ××” ×”×”×‘×“×œ ×‘×™×Ÿ two-stage (Faster R-CNN) ×•Ö¾one-stage (YOLO)?
* ×œ××” ×‘×•×—×¨×™× Smooth L1 ×•×œ× L2?

---

## 3. **Semantic Segmentation**

**×”×¡×‘×¨:** × ×•×ª× ×™× label ×œ×›×œ ×¤×™×§×¡×œ ×‘×ª××•× ×”.

```python
class SimpleSegmentation(nn.Module):
    def __init__(self, num_classes=21):
        super().__init__()
        backbone = models.resnet18(weights=None)
        self.encoder = nn.Sequential(*list(backbone.children())[:-2])  
        # input: [B, 3, 224, 224]
        # output: [B, 512, 7, 7]
        self.decoder = nn.ConvTranspose2d(512, num_classes, 16, stride=8, padding=4)
        # output: [B, num_classes, 224, 224]

    def forward(self, x):
        feats = self.encoder(x)  # [B, 512, 7, 7]
        out = self.decoder(feats)  # [B, num_classes, 224, 224]
        return out
```

```python
criterion = nn.CrossEntropyLoss()
```

**××•×“×œ×™× ×’×“×•×œ×™×:** DeepLabV3, SegFormer, PSPNet.

**×©××œ×•×ª ××§×¦×•×¢×™×•×ª:**

* ××” ×”×”×‘×“×œ ×‘×™×Ÿ Semantic Segmentation ×œÖ¾Instance Segmentation?
* ×œ××” ×œ×”×©×ª××© ×‘Ö¾dilated convolutions?
* ××™×š ××ª××•×“×“×™× ×¢× ×—×•×¡×¨ ××™×–×•×Ÿ ×‘××¡×¤×¨ ×”×¤×™×§×¡×œ×™× ×‘×™×Ÿ ××—×œ×§×•×ª?

---

## 4. **Instance Segmentation**

**×”×¡×‘×¨:** ××¡×•×•×’×™× ×¤×™×§×¡×œ×™× ××‘×œ ×’× ××¤×¨×™×“×™× ×‘×™×Ÿ ××•×¤×¢×™× ×©×•× ×™× ×©×œ ××•×ª×• ××•×‘×™×™×§×˜.

```python
class SimpleInstanceSeg(nn.Module):
    def __init__(self, num_classes=10):
        super().__init__()
        backbone = models.resnet18(weights=None)
        self.encoder = nn.Sequential(*list(backbone.children())[:-2])  
        self.mask_head = nn.Conv2d(512, num_classes, kernel_size=1)
        self.box_head = nn.Linear(512, 4)

    def forward(self, x):
        feats = self.encoder(x)  # [B, 512, 7, 7]
        pooled = feats.mean(dim=[2,3])  # [B, 512]
        boxes = self.box_head(pooled)  # [B, 4]
        masks = self.mask_head(feats)  # [B, num_classes, 7, 7]
        return boxes, masks
```

```python
cls_loss = nn.CrossEntropyLoss()
bbox_loss = nn.SmoothL1Loss()
mask_loss = nn.BCEWithLogitsLoss()
```

**××•×“×œ×™× ×’×“×•×œ×™×:** Mask R-CNN, YOLACT, SOLOv2.

**×©××œ×•×ª ××§×¦×•×¢×™×•×ª:**

* ××™×š ××¤×¨×™×“×™× ××•×¤×¢×™× ×©×•× ×™× ×××•×ª×• class?
* ×œ××” BCEWithLogitsLoss ×œ××¡×›×” ×•×œ× CrossEntropyLoss?
* ××” ×”×”×‘×“×œ ×‘×™×Ÿ ROI Pooling ×œÖ¾ROI Align?

---

## 5. **Depth Estimation**

**×”×¡×‘×¨:** ××—×–×™×¨×™× ×¢×¨×š ×¢×•××§ ×œ×›×œ ×¤×™×§×¡×œ (distance ××”××¦×œ××”).

```python
class DepthEstimation(nn.Module):
    def __init__(self):
        super().__init__()
        backbone = models.resnet18(weights=None)
        self.encoder = nn.Sequential(*list(backbone.children())[:-2])
        self.decoder = nn.ConvTranspose2d(512, 1, 16, stride=8, padding=4)
        # input: [B, 3, 224, 224]
        # output: [B, 1, 224, 224]

    def forward(self, x):
        feats = self.encoder(x)
        depth = self.decoder(feats)
        return depth
```

```python
criterion = nn.L1Loss()
```

**××•×“×œ×™× ×’×“×•×œ×™×:** Monodepth2, DPT.

**×©××œ×•×ª ××§×¦×•×¢×™×•×ª:**

* ×œ××” L1Loss ×¢×“×™×£ ×¢×œ L2 ×‘×¢×•××§?
* ××™×š ××¤×©×¨ ×œ×”×•×¡×™×£ supervision ×—×œ×§×™ ×›×©××™×Ÿ ground truth ××œ×?
* ××” ×”×”×‘×“×œ ×‘×™×Ÿ monocular depth ×œÖ¾stereo depth?

---

## 6. **Optical Flow**

**×”×¡×‘×¨:** ××•×“×“×™× ××ª ×ª× ×•×¢×ª ×”×¤×™×§×¡×œ×™× ×‘×™×Ÿ ×©×ª×™ ×ª××•× ×•×ª ×¢×•×§×‘×•×ª.

```python
class OpticalFlowNet(nn.Module):
    def __init__(self):
        super().__init__()
        self.encoder = nn.Conv2d(6, 64, 7, stride=2, padding=3)
        self.decoder = nn.ConvTranspose2d(64, 2, 16, stride=8, padding=4)
        # input: [B, 6, 224, 224] (2 ×ª××•× ×•×ª ×™×—×“)
        # output: [B, 2, 224, 224] (dx, dy ×œ×›×œ ×¤×™×§×¡×œ)

    def forward(self, img1, img2):
        x = torch.cat([img1, img2], dim=1)
        feats = self.encoder(x)
        flow = self.decoder(feats)
        return flow
```

```python
criterion = nn.MSELoss()
```

**××•×“×œ×™× ×’×“×•×œ×™×:** FlowNet2, RAFT.

**×©××œ×•×ª ××§×¦×•×¢×™×•×ª:**

* ×œ××” output ×”×•× 2-×¢×¨×•×¦×™×?
* ××” ×”×”×‘×“×œ ×‘×™×Ÿ forward flow ×•-backward flow?
* ××™×š ×‘×•×“×§×™× ×‘×™×¦×•×¢×™× (EPE metric)?

---

(×™×© ×¢×•×“: Lane Detection, Trajectory Prediction, Anomaly Detection, Captioning, SR, Inpainting â€“ ×× ×™ ×××©×™×š ×‘×¡×’× ×•×Ÿ ×”×–×” ×× ×ª×¨×¦×”).

---

×¨×•×¦×” ×©×××©×™×š ×•××‘× ×” ×œ×š ××ª **×›×œ ×©××¨ ×”××©×™××•×ª** ×‘××•×ª×• ×¤×•×¨××˜ ××¡×•×“×¨ (×›×•×œ×œ lane detection, captioning, inpainting ×•×›×•') ××• ×©× ×ª××§×“ ×‘×›××” ×¡×¤×¦×™×¤×™×•×ª ×©××¢× ×™×™× ×•×ª ××•×ª×š ×œ×¨××™×•×Ÿ?
