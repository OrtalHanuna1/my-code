{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "952da173",
   "metadata": {},
   "source": [
    "\n",
    "# Vision Multi-Task Notebook — Custom Models (runnable)\n",
    "This notebook provides **self-contained implementations** of several vision tasks **using models written here** (no external pretrained models for the core custom architectures).\n",
    "It also keeps the option to **load torchvision's ResNet50** for classification if you want to compare.\n",
    "\n",
    "Features present for every task:\n",
    "1. Dataset balance check\n",
    "2. Augmentations using `torchvision.transforms`\n",
    "3. Downloading datasets from torchvision (where appropriate) or generating small synthetic datasets so training is runnable\n",
    "4. Ability to load an external pretrained model (ResNet50) for classification as an option\n",
    "5. Loading a checkpoint if it exists\n",
    "6. Saving checkpoints during training\n",
    "7. Inference function that loads checkpoint and runs model on sample images\n",
    "8. Plots: data samples, model predictions, loss curves, and TensorBoard logging\n",
    "\n",
    "Tasks included (each is runnable):\n",
    "- Classification (CIFAR10) — Custom small CNN + optional ResNet50 head\n",
    "- Semantic Segmentation — Small UNet trained on synthetic shapes dataset\n",
    "- Super-Resolution — SRCNN trained on CIFAR10 downsampled images\n",
    "- GAN (DCGAN) — Generator/Discriminator trained on MNIST\n",
    "- Simple Object Detection (toy) — single-object images with one rectangle; model predicts box coords + class\n",
    "- Keypoint Regression (toy) — predict single keypoint in synthetic images (circle center)\n",
    "\n",
    "Run cells per-section. Heavy training cells are small by default (1-3 epochs) as smoke-tests — increase epochs for real training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9055c925",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEVICE = cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ortalhanuna/my-code/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Utilities: plotting, checkpointing, tensorboard logging, balance check, augmentations\n",
    "import os, math, torch, torch.nn as nn, torch.optim as optim\n",
    "import torchvision, torchvision.transforms as T\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "import random\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw\n",
    "\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('DEVICE =', DEVICE)\n",
    "\n",
    "def check_data_balance(dataset, name='dataset'):\n",
    "    labels = []\n",
    "    if hasattr(dataset, '__len__') and len(dataset)>0:\n",
    "        for i in range(min(len(dataset), 10000)):  # limit for speed\n",
    "            item = dataset[i]\n",
    "            if isinstance(item, tuple) and len(item)>1:\n",
    "                y = item[1]\n",
    "            else:\n",
    "                y = item\n",
    "            # handle when y is dict or tensor\n",
    "            if isinstance(y, dict) and 'label' in y:\n",
    "                y = y['label']\n",
    "            if isinstance(y, torch.Tensor):\n",
    "                y = y.item() if y.numel()==1 else y.tolist()\n",
    "            labels.append(y)\n",
    "    counter = Counter(labels)\n",
    "    print(f'=== Balance for {name} (showing up to 20 classes) ===')\n",
    "    for k,c in list(counter.items())[:20]:\n",
    "        print(f'class {k}: {c}')\n",
    "    return counter\n",
    "\n",
    "def imshow(img, title=None, unnormalize=True):\n",
    "    if isinstance(img, torch.Tensor):\n",
    "        img = img.cpu()\n",
    "        if unnormalize:\n",
    "            img = img*0.5 + 0.5\n",
    "        img = img.permute(1,2,0).numpy()\n",
    "    plt.imshow(img)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.axis('off')\n",
    "\n",
    "def imshow_batch(images, titles=None, n=6):\n",
    "    plt.figure(figsize=(15,3))\n",
    "    for i in range(n):\n",
    "        plt.subplot(1,n,i+1)\n",
    "        im = images[i]\n",
    "        imshow(im, title=(titles[i] if titles else None))\n",
    "\n",
    "def save_checkpoint(model, optimizer, epoch, path):\n",
    "    os.makedirs(os.path.dirname(path) or '.', exist_ok=True)\n",
    "    torch.save({'model_state': model.state_dict(), 'optim_state': optimizer.state_dict() if optimizer else None, 'epoch': epoch}, path)\n",
    "    print('Saved checkpoint to', path)\n",
    "\n",
    "def load_checkpoint_if_exists(model, optimizer, path):\n",
    "    if os.path.exists(path):\n",
    "        ckpt = torch.load(path, map_location=DEVICE)\n",
    "        model.load_state_dict(ckpt['model_state'])\n",
    "        if optimizer and ckpt.get('optim_state') is not None:\n",
    "            optimizer.load_state_dict(ckpt['optim_state'])\n",
    "        print('Loaded checkpoint from', path, 'epoch', ckpt.get('epoch'))\n",
    "        return ckpt.get('epoch',0)\n",
    "    else:\n",
    "        print('No checkpoint at', path)\n",
    "        return 0\n",
    "\n",
    "def make_writer(logdir='runs/exp'):\n",
    "    os.makedirs(logdir, exist_ok=True)\n",
    "    return SummaryWriter(logdir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "620f674b",
   "metadata": {},
   "source": [
    "\n",
    "## Classification — Custom CNN (optionally compare with torchvision ResNet50)\n",
    "\n",
    "Dataset: CIFAR10 (downloaded via torchvision).\n",
    "\n",
    "We provide:\n",
    "- Custom simple CNN defined below\n",
    "- Option to use torchvision.models.resnet50 (not pretrained by default) for comparison\n",
    "- Full training loop, checkpointing, inference, plotting, TensorBoard logging\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b59f5dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Classification: data loaders, models, train/eval, inference\n",
    "from torchvision import datasets, models\n",
    "\n",
    "def get_cifar10_loaders(batch_size=128, augment=True):\n",
    "    mean, std = (0.4914, 0.4822, 0.4465), (0.247,0.243,0.261)\n",
    "    if augment:\n",
    "        train_tfms = T.Compose([T.RandomHorizontalFlip(), T.RandomCrop(32, padding=4), T.ToTensor(), T.Normalize(mean,std)])\n",
    "    else:\n",
    "        train_tfms = T.Compose([T.ToTensor(), T.Normalize(mean,std)])\n",
    "    test_tfms = T.Compose([T.ToTensor(), T.Normalize(mean,std)])\n",
    "    train_set = datasets.CIFAR10('./data', train=True, download=True, transform=train_tfms)\n",
    "    test_set = datasets.CIFAR10('./data', train=False, download=True, transform=test_tfms)\n",
    "    return DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=2), DataLoader(test_set, batch_size=batch_size, shuffle=False, num_workers=2), train_set.classes, train_set\n",
    "\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super().__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3,32,3,padding=1), nn.ReLU(), nn.BatchNorm2d(32),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32,64,3,padding=1), nn.ReLU(), nn.BatchNorm2d(64),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(64,128,3,padding=1), nn.ReLU(), nn.BatchNorm2d(128),\n",
    "            nn.AdaptiveAvgPool2d(1)\n",
    "        )\n",
    "        self.classifier = nn.Linear(128, num_classes)\n",
    "    def forward(self,x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.classifier(x)\n",
    "\n",
    "def train_classification(model, train_loader, test_loader, epochs=3, lr=1e-3, ckpt_path='ckpts/cls.pth', use_tensorboard=True):\n",
    "    model = model.to(DEVICE)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    start_epoch = load_checkpoint_if_exists(model, optimizer, ckpt_path)\n",
    "    writer = make_writer('runs/classification') if use_tensorboard else None\n",
    "    history = {'train_loss':[], 'train_acc':[], 'val_loss':[], 'val_acc':[]}\n",
    "    for e in range(start_epoch, epochs):\n",
    "        model.train()\n",
    "        total_loss, total, correct = 0,0,0\n",
    "        for x,y in tqdm(train_loader):\n",
    "            x,y = x.to(DEVICE), y.to(DEVICE)\n",
    "            optimizer.zero_grad()\n",
    "            out = model(x)\n",
    "            loss = criterion(out,y)\n",
    "            loss.backward(); optimizer.step()\n",
    "            total_loss += loss.item()*x.size(0)\n",
    "            _,pred = out.max(1); correct += pred.eq(y).sum().item(); total += y.size(0)\n",
    "        train_loss = total_loss/len(train_loader.dataset); train_acc = correct/total\n",
    "        val_loss, val_acc = eval_classification(model, test_loader, criterion)\n",
    "        history['train_loss'].append(train_loss); history['train_acc'].append(train_acc)\n",
    "        history['val_loss'].append(val_loss); history['val_acc'].append(val_acc)\n",
    "        print(f'Epoch {e+1}/{epochs} train_loss={train_loss:.4f} train_acc={train_acc:.4f} val_loss={val_loss:.4f} val_acc={val_acc:.4f}')\n",
    "        if writer:\n",
    "            writer.add_scalars('loss', {'train':train_loss, 'val':val_loss}, e)\n",
    "            writer.add_scalars('acc', {'train':train_acc, 'val':val_acc}, e)\n",
    "        save_checkpoint(model, optimizer, e+1, ckpt_path)\n",
    "    if writer: writer.close()\n",
    "    return history\n",
    "\n",
    "def eval_classification(model, loader, criterion):\n",
    "    model.eval()\n",
    "    total_loss, total, correct = 0,0,0\n",
    "    with torch.no_grad():\n",
    "        for x,y in loader:\n",
    "            x,y = x.to(DEVICE), y.to(DEVICE)\n",
    "            out = model(x); loss = criterion(out,y)\n",
    "            total_loss += loss.item()*x.size(0)\n",
    "            _,pred = out.max(1); correct += pred.eq(y).sum().item(); total += y.size(0)\n",
    "    return total_loss/len(loader.dataset), correct/total\n",
    "\n",
    "def inference_classification(ckpt_path, dataloader, model_builder='custom', num_classes=10):\n",
    "    if model_builder=='resnet50':\n",
    "        model = models.resnet50(pretrained=False); model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "    else:\n",
    "        model = SimpleCNN(num_classes=num_classes)\n",
    "    _ = load_checkpoint_if_exists(model, None, ckpt_path)\n",
    "    model = model.to(DEVICE).eval()\n",
    "    imgs, labels = next(iter(dataloader))\n",
    "    imgs_cpu = imgs.clone()\n",
    "    imgs, labels = imgs.to(DEVICE), labels.to(DEVICE)\n",
    "    with torch.no_grad():\n",
    "        out = model(imgs)\n",
    "        _, preds = out.max(1)\n",
    "    # plot few\n",
    "    titles = [f'P:{preds[i].item()} / G:{labels[i].item()}' for i in range(6)]\n",
    "    imshow_batch(imgs_cpu, titles, n=6)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d0110c",
   "metadata": {},
   "source": [
    "\n",
    "## Semantic Segmentation — UNet on Synthetic Shapes\n",
    "\n",
    "We generate synthetic images with random colored rectangles/circles on a background and create pixel-wise masks for training a small UNet.\n",
    "This makes the example fully runnable without heavy datasets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21893c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Synthetic segmentation dataset\n",
    "class ShapesDataset(Dataset):\n",
    "    def __init__(self, n=1000, size=128, transforms=None):\n",
    "        self.n = n; self.size = size; self.transforms = transforms\n",
    "    def __len__(self): return self.n\n",
    "    def __getitem__(self, idx):\n",
    "        # create blank image and mask\n",
    "        img = Image.new('RGB', (self.size,self.size), (0,0,0))\n",
    "        mask = Image.new('L', (self.size,self.size), 0)\n",
    "        draw = ImageDraw.Draw(img); md = ImageDraw.Draw(mask)\n",
    "        # random shape\n",
    "        shape_type = random.choice(['rect','circle'])\n",
    "        if shape_type=='rect':\n",
    "            x0 = random.randint(10,self.size//2); y0 = random.randint(10,self.size//2)\n",
    "            x1 = random.randint(self.size//2,self.size-10); y1 = random.randint(self.size//2,self.size-10)\n",
    "            color = tuple(random.randint(50,255) for _ in range(3))\n",
    "            draw.rectangle([x0,y0,x1,y1], fill=color)\n",
    "            md.rectangle([x0,y0,x1,y1], fill=1)\n",
    "        else:\n",
    "            cx = random.randint(20,self.size-20); cy = random.randint(20,self.size-20); r = random.randint(10, self.size//3)\n",
    "            color = tuple(random.randint(50,255) for _ in range(3))\n",
    "            draw.ellipse([cx-r,cy-r,cx+r,cy+r], fill=color)\n",
    "            md.ellipse([cx-r,cy-r,cx+r,cy+r], fill=1)\n",
    "        img_t = T.ToTensor()(img)*2-1  # range [-1,1]\n",
    "        mask_t = torch.from_numpy(np.array(mask)).long()\n",
    "        mask_t = (mask_t>0).long()\n",
    "        return img_t, mask_t\n",
    "\n",
    "# Simple UNet\n",
    "class DoubleConv(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(nn.Conv2d(in_ch,out_ch,3,padding=1), nn.ReLU(), nn.Conv2d(out_ch,out_ch,3,padding=1), nn.ReLU())\n",
    "    def forward(self,x): return self.net(x)\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, n_classes=2):\n",
    "        super().__init__()\n",
    "        self.d1 = DoubleConv(3,32); self.p1 = nn.MaxPool2d(2)\n",
    "        self.d2 = DoubleConv(32,64); self.p2 = nn.MaxPool2d(2)\n",
    "        self.d3 = DoubleConv(64,128); self.up2 = nn.ConvTranspose2d(128,64,2,stride=2)\n",
    "        self.d4 = DoubleConv(128,64); self.up1 = nn.ConvTranspose2d(64,32,2,stride=2)\n",
    "        self.outc = nn.Conv2d(32,n_classes,1)\n",
    "    def forward(self,x):\n",
    "        x1 = self.d1(x); x2 = self.p1(x1)\n",
    "        x3 = self.d2(x2); x4 = self.p2(x3)\n",
    "        x5 = self.d3(x4); x6 = self.up2(x5)\n",
    "        x6 = torch.cat([x6,x3], dim=1); x7 = self.d4(x6)\n",
    "        x8 = self.up1(x7); x8 = torch.cat([x8,x1], dim=1)\n",
    "        return self.outc(x8)\n",
    "\n",
    "# training loop for segmentation (pixel-wise CE)\n",
    "def train_segmentation(model, train_loader, val_loader, epochs=3, lr=1e-3, ckpt='ckpts/seg.pth'):\n",
    "    model = model.to(DEVICE); opt = optim.Adam(model.parameters(), lr=lr); criterion = nn.CrossEntropyLoss()\n",
    "    start = load_checkpoint_if_exists(model, opt, ckpt)\n",
    "    writer = make_writer('runs/seg')\n",
    "    for e in range(start, epochs):\n",
    "        model.train()\n",
    "        tloss=0; tot=0\n",
    "        for x,y in tqdm(train_loader):\n",
    "            x,y = x.to(DEVICE), y.to(DEVICE)\n",
    "            opt.zero_grad(); out = model(x)  # (N,C,H,W)\n",
    "            loss = criterion(out, y)\n",
    "            loss.backward(); opt.step()\n",
    "            tloss += loss.item()*x.size(0); tot += x.size(0)\n",
    "        val_loss = 0\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for x,y in val_loader:\n",
    "                x,y = x.to(DEVICE), y.to(DEVICE)\n",
    "                out = model(x); val_loss += criterion(out,y).item()*x.size(0)\n",
    "        val_loss /= len(val_loader.dataset)\n",
    "        print(f'Epoch {e+1}/{epochs} train_loss={tloss/len(train_loader.dataset):.4f} val_loss={val_loss:.4f}')\n",
    "        writer.add_scalars('loss', {'train':tloss/len(train_loader.dataset),'val':val_loss}, e)\n",
    "        save_checkpoint(model, opt, e+1, ckpt)\n",
    "    writer.close()\n",
    "\n",
    "def inference_segmentation(ckpt, model, dataloader):\n",
    "    _ = load_checkpoint_if_exists(model, None, ckpt)\n",
    "    model.to(DEVICE).eval()\n",
    "    x,y = next(iter(dataloader))\n",
    "    with torch.no_grad():\n",
    "        out = model(x.to(DEVICE))\n",
    "        pred = out.argmax(1).cpu()\n",
    "    # plot\n",
    "    for i in range(4):\n",
    "        plt.figure(figsize=(8,3))\n",
    "        plt.subplot(1,3,1); imshow((x[i]+1)/2); plt.title('Image')\n",
    "        plt.subplot(1,3,2); plt.imshow(y[i].numpy()); plt.title('GT Mask'); plt.axis('off')\n",
    "        plt.subplot(1,3,3); plt.imshow(pred[i].numpy()); plt.title('Pred Mask'); plt.axis('off')\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4814853e",
   "metadata": {},
   "source": [
    "\n",
    "## Super-Resolution — SRCNN on CIFAR10 downsampled images\n",
    "A simple SRCNN-like model is trained to reconstruct CIFAR images from a downsampled+upsampled version.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b09296",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class SRCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(3,64,9,padding=4), nn.ReLU(),\n",
    "            nn.Conv2d(64,32,5,padding=2), nn.ReLU(),\n",
    "            nn.Conv2d(32,3,5,padding=2)\n",
    "        )\n",
    "    def forward(self,x): return self.net(x)\n",
    "\n",
    "def train_sr(model, train_loader, epochs=3, lr=1e-3, ckpt='ckpts/sr.pth'):\n",
    "    model = model.to(DEVICE); opt = optim.Adam(model.parameters(), lr=lr); criterion = nn.MSELoss()\n",
    "    start = load_checkpoint_if_exists(model, opt, ckpt)\n",
    "    writer = make_writer('runs/sr')\n",
    "    for e in range(start, epochs):\n",
    "        model.train(); total_loss=0\n",
    "        for x,_ in tqdm(train_loader):\n",
    "            # create low-res input\n",
    "            x = x.to(DEVICE)\n",
    "            lr = nn.functional.interpolate(x, scale_factor=0.5, mode='bilinear', align_corners=False)\n",
    "            lr_up = nn.functional.interpolate(lr, scale_factor=2.0, mode='bilinear', align_corners=False)\n",
    "            opt.zero_grad(); out = model(lr_up); loss = criterion(out, x); loss.backward(); opt.step()\n",
    "            total_loss += loss.item()*x.size(0)\n",
    "        avg = total_loss/len(train_loader.dataset)\n",
    "        print(f'Epoch {e+1}/{epochs} loss={avg:.6f}')\n",
    "        writer.add_scalar('loss/train', avg, e); save_checkpoint(model,opt,e+1,ckpt)\n",
    "    writer.close()\n",
    "\n",
    "def inference_sr(ckpt, model, dataloader):\n",
    "    _ = load_checkpoint_if_exists(model, None, ckpt)\n",
    "    model.to(DEVICE).eval()\n",
    "    imgs, _ = next(iter(dataloader))\n",
    "    imgs = imgs.to(DEVICE)\n",
    "    lr = nn.functional.interpolate(imgs, scale_factor=0.5, mode='bilinear', align_corners=False)\n",
    "    lr_up = nn.functional.interpolate(lr, scale_factor=2.0, mode='bilinear', align_corners=False)\n",
    "    with torch.no_grad():\n",
    "        out = model(lr_up).cpu()\n",
    "    # plot inputs and outputs\n",
    "    for i in range(4):\n",
    "        plt.figure(figsize=(8,3))\n",
    "        plt.subplot(1,3,1); imshow((imgs[i].cpu()+1)/2); plt.title('GT')\n",
    "        plt.subplot(1,3,2); imshow((lr_up[i].cpu()+1)/2); plt.title('LR upsampled')\n",
    "        plt.subplot(1,3,3); imshow((out[i]+1)/2); plt.title('SRCNN out')\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60486c46",
   "metadata": {},
   "source": [
    "\n",
    "## Generative Model — DCGAN on MNIST\n",
    "Simple DCGAN implementation using models defined in the notebook and training loop that saves checkpoints and plots samples.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aeaeec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# DCGAN generator and discriminator (MNIST)\n",
    "class DCGAN_G(nn.Module):\n",
    "    def __init__(self, zdim=100):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.ConvTranspose2d(zdim, 128, 4, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(128), nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(128, 64, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(64), nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(64, 1, 4, 2, 1, bias=False),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "    def forward(self,z): return self.net(z)\n",
    "\n",
    "class DCGAN_D(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(1,64,4,2,1), nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(64,128,4,2,1), nn.BatchNorm2d(128), nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Flatten(), nn.Linear(128*7*7,1), nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self,x): return self.net(x)\n",
    "\n",
    "def train_dcgan(G, D, dataloader, epochs=3, ckpt='ckpts/dcgan.pth'):\n",
    "    G, D = G.to(DEVICE), D.to(DEVICE)\n",
    "    optG = optim.Adam(G.parameters(), lr=2e-4, betas=(0.5,0.999))\n",
    "    optD = optim.Adam(D.parameters(), lr=2e-4, betas=(0.5,0.999))\n",
    "    criterion = nn.BCELoss()\n",
    "    start = 0\n",
    "    writer = make_writer('runs/dcgan')\n",
    "    for e in range(epochs):\n",
    "        for x,_ in tqdm(dataloader):\n",
    "            real = x.to(DEVICE)\n",
    "            bsz = real.size(0)\n",
    "            # train D\n",
    "            optD.zero_grad()\n",
    "            label_real = torch.ones(bsz,1, device=DEVICE); label_fake = torch.zeros(bsz,1, device=DEVICE)\n",
    "            out_real = D(real).view(-1,1); lossD_real = criterion(out_real, label_real)\n",
    "            z = torch.randn(bsz,100,1,1, device=DEVICE); fake = G(z)\n",
    "            out_fake = D(fake.detach()).view(-1,1); lossD_fake = criterion(out_fake, label_fake)\n",
    "            lossD = lossD_real + lossD_fake; lossD.backward(); optD.step()\n",
    "            # train G\n",
    "            optG.zero_grad(); out_fake2 = D(fake).view(-1,1); lossG = criterion(out_fake2, label_real); lossG.backward(); optG.step()\n",
    "        # log and save sample\n",
    "        print(f'Epoch {e+1}/{epochs} lossD={lossD.item():.4f} lossG={lossG.item():.4f}')\n",
    "        with torch.no_grad():\n",
    "            z = torch.randn(16,100,1,1, device=DEVICE); samples = G(z).cpu()\n",
    "        fig, axs = plt.subplots(1,8, figsize=(12,2))\n",
    "        for i in range(8):\n",
    "            axs[i].imshow((samples[i,0]+1)/2, cmap='gray'); axs[i].axis('off')\n",
    "        plt.show()\n",
    "        save_checkpoint(G, optG, e+1, ckpt + '_G')\n",
    "        save_checkpoint(D, optD, e+1, ckpt + '_D')\n",
    "    writer.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0bac994",
   "metadata": {},
   "source": [
    "\n",
    "## Toy Object Detection — Single-object bounding box regression (synthetic dataset)\n",
    "\n",
    "We create images with one colored rectangle; the model predicts bounding box coordinates (x_min,y_min,x_max,y_max) normalized to [0,1] and class (single class).\n",
    "This is a simplified detection setup (not COCO format), but it's fully trainable and demonstrates checkpointing and inference.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0edf3698",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Synthetic detection dataset\n",
    "class BoxDataset(Dataset):\n",
    "    def __init__(self, n=1000, size=128, transforms=None):\n",
    "        self.n=n; self.size=size; self.transforms=transforms\n",
    "    def __len__(self): return self.n\n",
    "    def __getitem__(self, idx):\n",
    "        img = Image.new('RGB',(self.size,self.size),(0,0,0)); draw=ImageDraw.Draw(img)\n",
    "        x0 = random.randint(5, self.size//2); y0 = random.randint(5, self.size//2)\n",
    "        x1 = random.randint(self.size//2, self.size-5); y1 = random.randint(self.size//2, self.size-5)\n",
    "        color = tuple(random.randint(50,255) for _ in range(3)); draw.rectangle([x0,y0,x1,y1], fill=color)\n",
    "        img_t = T.ToTensor()(img)*2-1\n",
    "        # normalized box coords and class 0\n",
    "        box = torch.tensor([x0/self.size, y0/self.size, x1/self.size, y1/self.size], dtype=torch.float32)\n",
    "        cls = torch.tensor(0, dtype=torch.long)\n",
    "        return img_t, {'box':box, 'label':cls}\n",
    "\n",
    "# Simple detection model: feature extractor + head for bbox regression + classification\n",
    "class SimpleDet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.backbone = nn.Sequential(nn.Conv2d(3,32,3,padding=1), nn.ReLU(), nn.MaxPool2d(2),\n",
    "                                      nn.Conv2d(32,64,3,padding=1), nn.ReLU(), nn.MaxPool2d(2),\n",
    "                                      nn.AdaptiveAvgPool2d(1))\n",
    "        self.fc_box = nn.Linear(64,4)\n",
    "        self.fc_cls = nn.Linear(64,1)\n",
    "    def forward(self,x):\n",
    "        f = self.backbone(x).view(x.size(0), -1)\n",
    "        box = torch.sigmoid(self.fc_box(f))  # normalized\n",
    "        cls = torch.sigmoid(self.fc_cls(f)).squeeze(1)\n",
    "        return box, cls\n",
    "\n",
    "def train_detection(model, dataset, epochs=5, batch_size=32, ckpt='ckpts/det.pth'):\n",
    "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "    model = model.to(DEVICE); opt = optim.Adam(model.parameters(), lr=1e-3)\n",
    "    l1 = nn.L1Loss(); bce = nn.BCELoss()\n",
    "    start = load_checkpoint_if_exists(model, opt, ckpt)\n",
    "    writer = make_writer('runs/det')\n",
    "    for e in range(start, epochs):\n",
    "        model.train(); total_loss=0\n",
    "        for x,y in tqdm(loader):\n",
    "            x = x.to(DEVICE)\n",
    "            boxes = torch.stack([item['box'] for item in y]).to(DEVICE)\n",
    "            labels = torch.stack([item['label'] for item in y]).float().to(DEVICE)\n",
    "            opt.zero_grad(); pred_box, pred_cls = model(x)\n",
    "            loss = l1(pred_box, boxes) + bce(pred_cls, labels)\n",
    "            loss.backward(); opt.step()\n",
    "            total_loss += loss.item()*x.size(0)\n",
    "        avg = total_loss/len(loader.dataset)\n",
    "        print(f'Epoch {e+1}/{epochs} loss={avg:.4f}')\n",
    "        writer.add_scalar('loss/train', avg, e); save_checkpoint(model,opt,e+1,ckpt)\n",
    "    writer.close()\n",
    "\n",
    "def inference_detection(ckpt, model, dataset):\n",
    "    _ = load_checkpoint_if_exists(model, None, ckpt)\n",
    "    model.to(DEVICE).eval()\n",
    "    x,y = dataset[0]\n",
    "    with torch.no_grad():\n",
    "        box, cls = model(x.unsqueeze(0).to(DEVICE))\n",
    "    box = box[0].cpu().numpy()*dataset.size\n",
    "    print('Pred box coords (px):', box)\n",
    "    # show image with box\n",
    "    img = (x+1)/2; plt.imshow(img.permute(1,2,0)); ax=plt.gca()\n",
    "    rect = plt.Rectangle((box[0],box[1]), box[2]-box[0], box[3]-box[1], edgecolor='r', facecolor='none', linewidth=2); ax.add_patch(rect)\n",
    "    plt.axis('off'); plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c0e408",
   "metadata": {},
   "source": [
    "\n",
    "## Keypoint Regression — Predict center of a circle (synthetic)\n",
    "\n",
    "We create images with a single filled circle and train a model to regress its (x,y) center normalized to [0,1].\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a72bb92",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class KeypointDataset(Dataset):\n",
    "    def __init__(self, n=1000, size=128):\n",
    "        self.n=n; self.size=size\n",
    "    def __len__(self): return self.n\n",
    "    def __getitem__(self, idx):\n",
    "        img = Image.new('RGB',(self.size,self.size),(0,0,0)); draw=ImageDraw.Draw(img)\n",
    "        cx = random.randint(20,self.size-20); cy = random.randint(20,self.size-20); r=random.randint(5,20)\n",
    "        color = tuple(random.randint(50,255) for _ in range(3))\n",
    "        draw.ellipse([cx-r,cy-r,cx+r,cy+r], fill=color)\n",
    "        img_t = T.ToTensor()(img)*2-1\n",
    "        kp = torch.tensor([cx/self.size, cy/self.size], dtype=torch.float32)\n",
    "        return img_t, kp\n",
    "\n",
    "class KeypointModel(nn.Module):\n",
    "    def __init__(self): super().__init__(); self.net = nn.Sequential(\n",
    "        nn.Conv2d(3,32,3,padding=1), nn.ReLU(), nn.MaxPool2d(2),\n",
    "        nn.Conv2d(32,64,3,padding=1), nn.ReLU(), nn.MaxPool2d(2),\n",
    "        nn.AdaptiveAvgPool2d(1), nn.Flatten(), nn.Linear(64,2)\n",
    "    )\n",
    "    def forward(self,x): return torch.sigmoid(self.net(x))  # normalized\n",
    "\n",
    "def train_keypoint(model, dataset, epochs=5, batch_size=32, ckpt='ckpts/kp.pth'):\n",
    "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "    model = model.to(DEVICE); opt = optim.Adam(model.parameters(), lr=1e-3); lossf = nn.MSELoss()\n",
    "    start = load_checkpoint_if_exists(model,opt,ckpt); writer=make_writer('runs/kp')\n",
    "    for e in range(start, epochs):\n",
    "        model.train(); total=0\n",
    "        for x,y in tqdm(loader):\n",
    "            x,y = x.to(DEVICE), y.to(DEVICE)\n",
    "            opt.zero_grad(); pred = model(x); loss = lossf(pred,y); loss.backward(); opt.step()\n",
    "            total += loss.item()*x.size(0)\n",
    "        print(f'Epoch {e+1}/{epochs} loss={total/len(loader.dataset):.6f}'); writer.add_scalar('loss/train', total/len(loader.dataset), e); save_checkpoint(model,opt,e+1,ckpt)\n",
    "    writer.close()\n",
    "\n",
    "def inference_kp(ckpt, model, dataset):\n",
    "    _ = load_checkpoint_if_exists(model, None, ckpt)\n",
    "    model.to(DEVICE).eval()\n",
    "    x,kp = dataset[0]\n",
    "    with torch.no_grad():\n",
    "        pred = model(x.unsqueeze(0).to(DEVICE)).cpu().numpy()[0]\n",
    "    img = (x+1)/2; plt.imshow(img.permute(1,2,0)); plt.scatter([pred[0]*dataset.size],[pred[1]*dataset.size], c='r'); plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6944f4fb",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "### How to use this notebook\n",
    "\n",
    "- Run the Utilities cell first.\n",
    "- For each task, run the dataset cell (or creation line), then the training cell to train, then the inference cell to visualize results.\n",
    "- Checkpoints are saved under `ckpts/` and TensorBoard logs under `runs/`.\n",
    "- Increase epochs for real training. The defaults are small for a quick runnable demo.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
